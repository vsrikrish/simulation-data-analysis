[
  {
    "objectID": "assignments/hw01/hw01.html",
    "href": "assignments/hw01/hw01.html",
    "title": "Homework 1: Debugging Julia Code",
    "section": "",
    "text": "Due Date\n\n\n\nFriday, 2/9/24, 9:00pm"
  },
  {
    "objectID": "assignments/hw01/hw01.html#overview",
    "href": "assignments/hw01/hw01.html#overview",
    "title": "Homework 1: Debugging Julia Code",
    "section": "Overview",
    "text": "Overview\n\nInstructions\n\nProblems 1-4 consist of a series of code snippets for you to interpret and debug. For Problems 1-3, you will be asked to identify relevant error(s) and fix the code. For Problem 4, the code works as intended; your goal is to identify the code’s purpose by following its logic.\nProblem 5 asks you to rewrite a “script” into a function, which you will then use to conduct an experiment.\n\n\n\nLoad Environment\nThe following code loads the environment and makes sure all needed packages are installed. This should be at the start of most Julia scripts.\n\nimport Pkg\nPkg.activate(@__DIR__)\nPkg.instantiate()\n\n  Activating project at `~/work/simulation-data-analysis/simulation-data-analysis/assignments/hw01`"
  },
  {
    "objectID": "assignments/hw01/hw01.html#problems-total-100-points",
    "href": "assignments/hw01/hw01.html#problems-total-100-points",
    "title": "Homework 1: Debugging Julia Code",
    "section": "Problems (Total: 100 Points)",
    "text": "Problems (Total: 100 Points)\n\nProblem 1 (20 points)\nYou’ve been tasked with writing code to identify the minimum value in an array. You cannot use a predefined function. Your colleague suggested the function below, but it does not return the minimum value.\n\nfunction minimum(array)\n    min_value = 0\n    for i in 1:length(array)\n        if array[i] &lt; min_value\n            min_value = array[i]\n        end\n    end\n    return min_value\nend\n\narray_values = [89, 90, 95, 100, 100, 78, 99, 98, 100, 95]\n@show minimum(array_values);\n\nminimum(array_values) = 0\n\n\n\nProblem 1.1 (10 points)\nDescribe the logic error.\n\n\nProblem 1.2 (5 points)\nWrite a fixed version of the function.\n\n\nProblem 1.3 (5 points)\nUse your fixed function to find the minimum value of array_values.\n\n\n\nProblem 2 (20 points)\nYour team is trying to compute the average grade for your class, but the following code produces an error.\n\nstudent_grades = [89, 90, 95, 100, 100, 78, 99, 98, 100, 95]\nfunction class_average(grades)\n  average_grade = mean(student_grades)\n  return average_grade\nend\n\n@show average_grade;\n\nLoadError: UndefVarError: average_grade not defined\n\n\n\nProblem 2.1 (10 points)\nDescribe the logic and/or syntax error.\n\n\nProblem 2.2 (5 points)\nWrite a fixed version of the code.\n\n\nProblem 2.3 (5 points)\nUse your fixed code to compute the average grade for the class.\n\n\n\nProblem 3 (20 points)\nYour team has collected data on the mileage of different car models. You want to calculate the average mileage per gallon (MPG) for the different cars, but your code produces the same value for all of the vehicles, which makes you suspicious.\n\nfunction calculate_MPG((miles, gallons))\n    return miles / gallons\nend\n\ncar_miles =  [(334, 11), (289, 15), (306, 12), (303, 20), (350, 20), (294, 14)]\n\nmpg = zeros(length(car_miles))\n\nfor i in 1:length(car_miles)\n    miles = car_miles[1][1]\n    gallon = car_miles[1][2]\n    mpg[i] = calculate_MPG((miles, gallon))\nend\n@show mpg;\n\nmpg = [30.363636363636363, 30.363636363636363, 30.363636363636363, 30.363636363636363, 30.363636363636363, 30.363636363636363]\n\n\n\nProblem 3.1 (10 points)\nDescribe the logic error.\n\n\nProblem 3.2 (5 points)\nWrite a fixed version of the code.\n\n\nProblem 3.3 (5 points)\nUse your fixed code to compute the MPGs.\n\n\n\nProblem 4 (20 points)\nYou’ve been handed some code to analyze. The original coder was not very considerate of other potential users: the function is called mystery_function and there are no comments explaining the purpose of the code. It appears to take in an array and return some numbers, and you’ve been assured that the code works as intended.\n\nfunction mystery_function(values)\n    y = []\n    for v in values\n        if !(v in y)\n            append!(y, v)\n        end\n    end\n    return y\nend\n\nlist_of_values = [1, 2, 3, 4, 3, 4, 2, 1]\n@show mystery_function(list_of_values);\n\nmystery_function(list_of_values) = Any[1, 2, 3, 4]\n\n\n\nProblem 4.1 (10 points)\nExplain the purpose of mystery_function.\n\n\nProblem 4.2 (10 points)\nAdd comments to the code, explaining why and how it works. Refer to “Best Practices for Writing Code Comments”, and remember that bad comments can be just as bad as no comments at all. You do not need to add comments to every line (in fact, this is very bad practice), but you should note the purpose of every “section” of code, and add comments explaining any code sequences that you don’t immediately understand."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Class Schedule",
    "section": "",
    "text": "This page contains a schedule of the topics, content, and assignments for the semester. Note that this schedule will be updated as necessary the semester progresses, with all changes documented here.\n\nI: Class Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture\nDate\nTopic\nSlides\nAE\nLab\nHW\nProject\n\n\n\n\n1\nMon, Jan 22\nWelcome to the Class!\n\n\n\n\n\n\n\n2\nWed, Jan 24\nJulia Basics and GitHub\n\n\n\n\n\n\n\n3\nFri, Jan 26\nLab 1: Julia Basics\n\n\n\n\n\n\n\n4\nMon, Jan 29\nExploratory Analysis and Data-Generating Processes\n\n\n\n\n\n\n\n5\nWed, Jan 31\nSimulation-based Data Analysis"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final Project",
    "section": "",
    "text": "The final project gives you an opportunity to use and extend the methods we have learned in class to an environmental data set and/or model of your choosing. More details will be provided over the semester. We will discuss each component in class as well as providing relevant information on this page."
  },
  {
    "objectID": "project.html#overview",
    "href": "project.html#overview",
    "title": "Final Project",
    "section": "",
    "text": "The final project gives you an opportunity to use and extend the methods we have learned in class to an environmental data set and/or model of your choosing. More details will be provided over the semester. We will discuss each component in class as well as providing relevant information on this page."
  },
  {
    "objectID": "project.html#overall-instructions",
    "href": "project.html#overall-instructions",
    "title": "Final Project",
    "section": "Overall Instructions",
    "text": "Overall Instructions\n\nStudents in 4850 should work in groups of 2-3, while students in 5850 must work alone."
  },
  {
    "objectID": "project.html#schedule",
    "href": "project.html#schedule",
    "title": "Final Project",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\nMilestone\nInstructions\nRubric\nDue Date\n\n\n\n\nProposal\n\n\nFri, Feb 23\n\n\nResearch Plan\n\n\nFri, Mar 29\n\n\nPoster\n\n\nWed, May 08"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About This Website",
    "section": "",
    "text": "This website contains course materials for the Spring 2024 edition of Environmental Data Analysis and Simulation, taught by Vivek Srikrishnan at Cornell University."
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About This Website",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMuch of the material for this course has evolved from discussions and work with Klaus Keller, Tony Wong, Casey Helgeson, Ben Seiyon Lee and James Doss-Gollin. Many thanks also to Andrew Gelman and Christian Robert, whose work heavily inspired many aspects of this course and which I refer back to regularly. Kieran Healy also wrote an outstanding book on Data Visualization which I learned a great deal from and still reference.\nThe layout for this site was also inspired by and draws from STA 210 at Duke University and Andrew Heiss’s course materials at Georgia State."
  },
  {
    "objectID": "about.html#tools-and-generation-workflow",
    "href": "about.html#tools-and-generation-workflow",
    "title": "About This Website",
    "section": "Tools and Generation Workflow",
    "text": "Tools and Generation Workflow\nThis website was built with Quarto, which allows me to integrate Julia code and output with the web content, pdfs, and slides in an amazingly clean fashion, while simplifying the process of generation. All materials can be generated through a simple workflow from the [GitHub Repository]."
  },
  {
    "objectID": "labs/lab01/lab01.html",
    "href": "labs/lab01/lab01.html",
    "title": "Lab 1: Getting Started with Julia",
    "section": "",
    "text": "Due Date\n\n\n\nFriday, 2/2/24, 9:00pm"
  },
  {
    "objectID": "labs/lab01/lab01.html#introduction",
    "href": "labs/lab01/lab01.html#introduction",
    "title": "Lab 1: Getting Started with Julia",
    "section": "Introduction",
    "text": "Introduction\n\nOverview\nThe goal of this lab is to get you up and running with Julia. You’ll start to be introduced to some of the basic syntax and workflow for data analysis in Julia, which we will build on over the course of the semester. We’ll do some stats without making this apparent, and later in the semester, we’ll formalize the type of analysis that you’ll complete in this lab.\nThis lab repeats the analysis from Statistics Without The Agonizing Pain by John Rauser (which is a neat watch!).\n\n\nLearning Objectives\nAfter completing this lab, students wil be able to:\n\nwrite functions in Julia;\nsimulate alternative datasets to test a hypothesis;\nmake plots to compare summaries of observed datasets to alternatives."
  },
  {
    "objectID": "labs/lab01/lab01.html#setup",
    "href": "labs/lab01/lab01.html#setup",
    "title": "Lab 1: Getting Started with Julia",
    "section": "Setup",
    "text": "Setup\n\nLoading Packages\nThe first step in any Julia script or program is to load the environment, which contains any needed packages. To keep things efficient, “base” Julia contains relatively minimal functionality, and additional packages can be installed and loaded to add new functions and tools. In Julia, package management is handled through the Pkg.jl module. Julia stores information about packages in two files: Project.toml and Manifest.toml, which is why these are included in all of your assignment repositories. You won’t need to touch these directly.\nThe following lines load Pkg.jl and activate the desired environment.\n\nusing Pkg # load Pkg.jl\nPkg.activate(@__DIR__) # load the environment based on the *.toml files in the same directory as the current file\nPkg.instantiate() # install any needed packages which are missing from the local install\nPkg.status() # print the packages available in the environment.\n\n  Activating project at `~/work/simulation-data-analysis/simulation-data-analysis/labs/lab01`\n   Installed JpegTurbo_jll ──────────────── v2.1.91+0\n   Installed libfdk_aac_jll ─────────────── v2.0.2+0\n   Installed GR_jll ─────────────────────── v0.71.8+0\n   Installed x265_jll ───────────────────── v3.5.0+0\n   Installed Libmount_jll ───────────────── v2.35.0+0\n   Installed LERC_jll ───────────────────── v3.0.0+1\n   Installed Opus_jll ───────────────────── v1.3.2+0\n   Installed LoggingExtras ──────────────── v1.0.0\n   Installed Xorg_xkbcomp_jll ───────────── v1.4.2+4\n   Installed Xorg_xcb_util_wm_jll ───────── v0.4.1+1\n   Installed Grisu ──────────────────────── v1.0.2\n   Installed Measures ───────────────────── v0.3.2\n   Installed RelocatableFolders ─────────── v1.0.0\n   Installed Xorg_xcb_util_image_jll ────── v0.4.0+1\n   Installed RecipesPipeline ────────────── v0.6.11\n   Installed PlotUtils ──────────────────── v1.3.4\n   Installed Xorg_libpthread_stubs_jll ──── v0.1.0+3\n   Installed OpenSSL ────────────────────── v1.3.3\n   Installed Contour ────────────────────── v0.6.2\n   Installed Xorg_libxkbfile_jll ────────── v1.1.0+4\n   Installed Cairo_jll ──────────────────── v1.16.1+1\n   Installed Fontconfig_jll ─────────────── v2.13.93+0\n   Installed Xorg_xcb_util_jll ──────────── v0.4.0+1\n   Installed Libgpg_error_jll ───────────── v1.42.0+0\n   Installed HTTP ───────────────────────── v1.7.4\n   Installed Xorg_libXinerama_jll ───────── v1.1.4+4\n   Installed Xorg_libXau_jll ────────────── v1.0.9+4\n   Installed FFMPEG ─────────────────────── v0.4.1\n   Installed IrrationalConstants ────────── v0.2.2\n   Installed Showoff ────────────────────── v1.0.3\n   Installed Qt5Base_jll ────────────────── v5.15.3+2\n   Installed Bzip2_jll ──────────────────── v1.0.8+0\n   Installed xkbcommon_jll ──────────────── v1.4.1+0\n   Installed Xorg_xcb_util_keysyms_jll ──── v0.4.0+1\n   Installed SimpleBufferStream ─────────── v1.1.0\n   Installed Pipe ───────────────────────── v1.3.0\n   Installed SpecialFunctions ───────────── v2.2.0\n   Installed HarfBuzz_jll ───────────────── v2.8.1+1\n   Installed PlotThemes ─────────────────── v3.1.0\n   Installed NaNMath ────────────────────── v1.0.2\n   Installed LZO_jll ────────────────────── v2.10.1+0\n   Installed fzf_jll ────────────────────── v0.29.0+0\n   Installed TranscodingStreams ─────────── v0.9.11\n   Installed FriBidi_jll ────────────────── v1.0.10+0\n   Installed x264_jll ───────────────────── v2021.5.5+0\n   Installed GLFW_jll ───────────────────── v3.3.8+0\n   Installed UnicodeFun ─────────────────── v0.4.1\n   Installed ColorSchemes ───────────────── v3.20.0\n   Installed FreeType2_jll ──────────────── v2.10.4+0\n   Installed Colors ─────────────────────── v0.12.10\n   Installed JLFzf ──────────────────────── v0.1.5\n   Installed Xorg_libxcb_jll ────────────── v1.13.0+3\n   Installed CodecZlib ──────────────────── v0.7.1\n   Installed libpng_jll ─────────────────── v1.6.38+0\n   Installed StatsAPI ───────────────────── v1.6.0\n   Installed libaom_jll ─────────────────── v3.4.0+0\n   Installed StatsBase ──────────────────── v0.33.21\n   Installed GR ─────────────────────────── v0.71.8\n   Installed Zstd_jll ───────────────────── v1.5.4+0\n   Installed Xorg_libXext_jll ───────────── v1.3.4+4\n   Installed Expat_jll ──────────────────── v2.4.8+0\n   Installed Scratch ────────────────────── v1.2.0\n   Installed ColorTypes ─────────────────── v0.11.4\n   Installed TensorCore ─────────────────── v0.1.1\n   Installed Plots ──────────────────────── v1.38.8\n   Installed Libtiff_jll ────────────────── v4.4.0+0\n   Installed Libffi_jll ─────────────────── v3.2.2+1\n   Installed ColorVectorSpace ───────────── v0.9.10\n   Installed Xorg_libXrender_jll ────────── v0.9.10+4\n   Installed Ogg_jll ────────────────────── v1.3.5+1\n   Installed Xorg_libXi_jll ─────────────── v1.7.10+4\n   Installed OrderedCollections ─────────── v1.6.0\n   Installed XSLT_jll ───────────────────── v1.1.34+0\n   Installed ChainRulesCore ─────────────── v1.15.7\n   Installed LogExpFunctions ────────────── v0.3.23\n   Installed Xorg_libXcursor_jll ────────── v1.2.0+4\n   Installed OpenSpecFun_jll ────────────── v0.5.5+0\n   Installed Libuuid_jll ────────────────── v2.36.0+0\n   Installed Xorg_xcb_util_renderutil_jll ─ v0.3.9+1\n   Installed Wayland_protocols_jll ──────── v1.25.0+0\n   Installed InverseFunctions ───────────── v0.1.8\n   Installed Graphite2_jll ──────────────── v1.3.14+0\n   Installed DocStringExtensions ────────── v0.9.3\n   Installed Pixman_jll ─────────────────── v0.40.1+0\n   Installed libass_jll ─────────────────── v0.15.1+0\n   Installed XML2_jll ───────────────────── v2.10.3+0\n   Installed Gettext_jll ────────────────── v0.21.0+0\n   Installed Wayland_jll ────────────────── v1.21.0+0\n   Installed Xorg_xtrans_jll ────────────── v1.4.0+3\n   Installed OpenSSL_jll ────────────────── v1.1.20+0\n   Installed BitFlags ───────────────────── v0.1.7\n   Installed FFMPEG_jll ─────────────────── v4.4.2+2\n   Installed Xorg_xkeyboard_config_jll ──── v2.27.0+4\n   Installed Libgcrypt_jll ──────────────── v1.8.7+0\n   Installed Xorg_libXfixes_jll ─────────── v5.0.3+4\n   Installed Xorg_libXrandr_jll ─────────── v1.5.2+4\n   Installed RecipesBase ────────────────── v1.3.3\n   Installed LAME_jll ───────────────────── v3.100.1+0\n   Installed FixedPointNumbers ──────────── v0.8.4\n   Installed Libglvnd_jll ───────────────── v1.6.0+0\n   Installed Xorg_libX11_jll ────────────── v1.6.9+4\n   Installed Libiconv_jll ───────────────── v1.16.1+2\n   Installed libvorbis_jll ──────────────── v1.3.7+1\n   Installed Xorg_libXdmcp_jll ──────────── v1.1.3+4\n   Installed Glib_jll ───────────────────── v2.74.0+2\n   Installed IniFile ────────────────────── v0.5.1\n   Installed URIs ───────────────────────── v1.4.2\n   Installed Unzip ──────────────────────── v0.2.0\n   Installed ChangesOfVariables ─────────── v0.1.6\nPrecompiling project...\n  ✓ StatsAPI\n  ✓ Contour\n  ✓ TensorCore\n  ✓ Pipe\n  ✓ OpenLibm_jll\n  ✓ Measures\n  ✓ InverseFunctions\n  ✓ Grisu\n  ✓ OrderedCollections\n  ✓ FixedPointNumbers\n  ✓ Unzip\n  ✓ IniFile\n  ✓ DocStringExtensions\n  ✓ SimpleBufferStream\n  ✓ URIs\n  ✓ IrrationalConstants\n  ✓ UnicodeFun\n  ✓ PCRE2_jll\n  ✓ BitFlags\n  ✓ TranscodingStreams\n  ✓ Scratch\n  ✓ ChainRulesCore\n  ✓ LoggingExtras\n  ✓ OpenSSL_jll\n  ✓ Graphite2_jll\n  ✓ Libmount_jll\n  ✓ RecipesBase\n  ✓ Bzip2_jll\n  ✓ Xorg_libXau_jll\n  ✓ libpng_jll\n  ✓ libfdk_aac_jll\n  ✓ Pixman_jll\n  ✓ LAME_jll\n  ✓ LERC_jll\n  ✓ fzf_jll\n  ✓ JpegTurbo_jll\n  ✓ Xorg_libXdmcp_jll\n  ✓ Ogg_jll\n  ✓ x265_jll\n  ✓ x264_jll\n  ✓ libaom_jll\n  ✓ Zstd_jll\n  ✓ Expat_jll\n  ✓ LZO_jll\n  ✓ Opus_jll\n  ✓ Xorg_xtrans_jll\n  ✓ Libiconv_jll\n  ✓ Libffi_jll\n  ✓ Wayland_protocols_jll\n  ✓ Libgpg_error_jll\n  ✓ OpenSpecFun_jll\n  ✓ FriBidi_jll\n  ✓ Xorg_libpthread_stubs_jll\n  ✓ Libuuid_jll\n  ✓ NaNMath\n  ✓ Showoff\n  ✓ Latexify\n  ✓ CodecZlib\n  ✓ DataStructures\n  ✓ RelocatableFolders\n  ✓ ColorTypes\n  ✓ FreeType2_jll\n  ✓ ChangesOfVariables\n  ✓ JLFzf\n  ✓ libvorbis_jll\n  ✓ XML2_jll\n  ✓ Libtiff_jll\n  ✓ OpenSSL\n  ✓ Libgcrypt_jll\n  ✓ SortingAlgorithms\n  ✓ Fontconfig_jll\n  ✓ Gettext_jll\n  ✓ Wayland_jll\n  ✓ LogExpFunctions\n  ✓ XSLT_jll\n  ✓ Glib_jll\n  ✓ Colors\n  ✓ HTTP\n  ✓ Xorg_libxcb_jll\n  ✓ StatsBase\n  ✓ Xorg_xcb_util_jll\n  ✓ Xorg_libX11_jll\n  ✓ Xorg_xcb_util_image_jll\n  ✓ Xorg_xcb_util_keysyms_jll\n  ✓ Xorg_xcb_util_renderutil_jll\n  ✓ Xorg_xcb_util_wm_jll\n  ✓ Xorg_libXrender_jll\n  ✓ Xorg_libXext_jll\n  ✓ Xorg_libXfixes_jll\n  ✓ Xorg_libxkbfile_jll\n  ✓ Libglvnd_jll\n  ✓ Xorg_libXinerama_jll\n  ✓ Xorg_libXrandr_jll\n  ✓ SpecialFunctions\n  ✓ Cairo_jll\n  ✓ Xorg_libXcursor_jll\n  ✓ Xorg_libXi_jll\n  ✓ Xorg_xkbcomp_jll\n  ✓ HarfBuzz_jll\n  ✓ GLFW_jll\n  ✓ Xorg_xkeyboard_config_jll\n  ✓ libass_jll\n  ✓ xkbcommon_jll\n  ✓ FFMPEG_jll\n  ✓ Qt5Base_jll\n  ✓ FFMPEG\n  ✓ ColorVectorSpace\n  ✓ GR_jll\n  ✓ GR\n  ✓ ColorSchemes\n  ✓ PlotUtils\n  ✓ RecipesPipeline\n  ✓ PlotThemes\n  ✓ Plots\n  114 dependencies successfully precompiled in 107 seconds. 27 already precompiled.\n\n\nStatus `~/work/simulation-data-analysis/simulation-data-analysis/labs/lab01/Project.toml`\n  [7073ff75] IJulia v1.24.0\n  [91a5bcdd] Plots v1.38.8\n  [2913bbd2] StatsBase v0.33.21\n  [9a3f8284] Random\n\n\nI will start all of your assignments and scripts with at least the first three of these lines (Pkg.status() can be useful when you don’t know what’s available, but won’t be necessary for our purposes going forward).\nIf you want to add additional packages for later use, you can do so with Pkg.add(). I’ve commented out these lines, as they are not needed, but feel free to uncomment and test: trying to add a package which is already in the environment won’t do anything harmful.\n\n# Pkg.add(\"Plots\") # add Plots.jl, the base plotting library, to the environment\n\nNow, we load the packages that we will need with the using keyword.\n\nusing Random # this loads functionality for random number generation\nusing StatsBase # this includes a bunch of statistical functions, including mean and quantile\nusing Plots # this loads Plots.jl\n\nAnd we’re all set! Because we provided the environment files, the rest of this notebook should work smoothly (assuming you’re using Julia 1.8.x), but if not, please ask or post about it!\n\n\n\n\n\n\nSometimes difficulties can emerge if the version of Julia is different. The first thing to try is to delete Manifest.toml and re-run Pkg.instantiate(), as this might resolve some issues related to package versions, though it runs the risk of a update changing some of the syntax. If you run into trouble, please bring it up on Ed Discussion, and we’ll work through it.\n\n\n\n\n\nLoad Data\nThe underlying question we would like to address is: what is the influence of drinking beer on the likelihood of being bitten by mosquitoes?\nFirst, we need to load the data. We will look at ways to work with structured data files later. For now, let’s just enter the data manually. We will do this using vectors, which are data structures which correspond to one-dimensional lists. To define a vector, enclose the values between two square brackets, [ and ]1 Line breaks don’t matter: Julia is smart enough to recognize that the procedure isn’t complete until it sees the closing bracket.1 There is some nuance about whether you separate values with commas or spaces, which determines if the resulting vector is a row vector or a column vector. This isn’t particularly relevant for this assignment, but can matter later.\nLet’s load data for the number of bites reported by the participants who drank beer.\n\nbeer = [27, 20, 21, 26, 27, 31, 24, 21, 20, 19, 23, 24, 28, 19, 24, 29, 18, 20, 17, 31, 20, 25, 28, 21, 27]\n\n25-element Vector{Int64}:\n 27\n 20\n 21\n 26\n 27\n 31\n 24\n 21\n 20\n 19\n 23\n 24\n 28\n 19\n 24\n 29\n 18\n 20\n 17\n 31\n 20\n 25\n 28\n 21\n 27\n\n\nWe can see what type of variable beer is by using the typeof function:\n\ntypeof(beer)\n\n\nVector{Int64} (alias for Array{Int64, 1})\n\n\n\nThis tells us that beer is a vector consisting of integers (which means they don’t include any decimals). Next, let’s load the data for the number of times participants who were drinking water were bitten.\n\nwater = [21, 22, 15, 12, 21, 16, 19, 15, 22, 24, 19, 23, 13, 22, 20, 24, 18, 20];\n\nNotice that, unlike when we created beer, we didn’t get any output from creating water. This is because we ended the statement with a semi-colon ;, which suppresses the output that would otherwise be displayed. This can be a convenient way to clean up the output of your code.\nAnother handy method for displaying variables is the @show macro. A macro is just a particular type of Julia function which starts with @ and is “applied” to some other code:\n\n@show water;\n\nwater = [21, 22, 15, 12, 21, 16, 19, 15, 22, 24, 19, 23, 13, 22, 20, 24, 18, 20]\n\n\nThe nice thing about using (show?) is that it explicitly tells us the name of the variable and what it equals. However, we do have to include the semi-colon, or else it will double-print the output.\n\n\nInitial Analysis\nHow can we determine if there’s a meaningful difference between these two sets of numbers? Naively, we might simply look at the different in means between the two datasets.\n\nobserved_difference = mean(beer) - mean(water)\n@show observed_difference;\n\nobserved_difference = 4.37777777777778\n\n\nThis tells us that the participants in the experiment who drank beer were bitten approximately 4.3 more times than the participants who drank water! Does that seem like a meaningful difference, or could it be the result of random chance? In this problem, we will use a simulation approach to address this question.\nSuppose someone is skeptical of the idea that drinking beer could result in a higher attraction to mosquitoes, and therefore more bites. To this skeptic, the two datasets are really just different samples from the same underlying population of people getting bitten by mosquitoes, rather than two different populations with different propensities for being bitten. If this is the case, then we can “shuffle” all of the measurements between the two datasets and re-compute the differences in the means, repeat this procedure a large number of times, and the difference between the two observed means should be captured by the distribution of possible differences."
  },
  {
    "objectID": "labs/lab01/lab01.html#problems",
    "href": "labs/lab01/lab01.html#problems",
    "title": "Lab 1: Getting Started with Julia",
    "section": "Problems",
    "text": "Problems\n\nProblem 1: Write a Simulation Function (10 points)\nWrite a function which:\n\ntakes in two vectors;\ncombines them (you can use the vcat() function to concatenate two column vectors);\nshuffles the combined vector (using the shuffle function);\nsplits this shuffled vector into two vectors with the length of the original data;\nreturns the difference between the means of these two vectors.\n\nWe’ve given you a starting skeleton function below; you just need to fill in the code. This may require some Googling to figure out the exact syntax, and you can consult the course website’s Julia Basics tutorial. Make sure to reference any consulted resources in the References section below!\n\n\n\n\n\n\nWhy Write a Function?\n\n\n\nWriting a function for code that you are going to re-use multiple times makes your program more organized and readable. Plus, if you find a bug, you only have to fix it in one place! Julia’s compiler also can better optimize code which is organized around functions.\n\n\n\n# the function name says that it does: try to use meaningful variable and and function names!\n# y1 and y2 are the input vectors\nfunction simulate_difference(y1, y2)\n# concatenate both vectors into a single vector\n\n# shuffle this new vector\n\n# split the shuffled vector into two vectors with the same lengths as y1 and y2\n\n# compute the difference in means between these two new vectors; call this \"difference\"\n\n# return the difference\nreturn difference\nend\n\nsimulate_difference (generic function with 1 method)\n\n\nApply your function to beer and water.\n\nsimulate_differences(beer, water)\n\nLoadError: UndefVarError: simulate_differences not defined\n\n\n\n\nProblem 2: Plot Simulations (5 points)\nGenerate 10,000 simulations by applying your function to beer and water repeatedly. The most straightforward way to do this is with a comprehension, which will automatically evaluate the function over a vector if inputs and return a vector. The general format for a comprehension is output = [function(var) for var in some_range].\nFor example, to compute the square of all of the integers between 0 and 10:\n\nsquares = [x^2 for x in 1:10]\n\n10-element Vector{Int64}:\n   1\n   4\n   9\n  16\n  25\n  36\n  49\n  64\n  81\n 100\n\n\nTo reuse a function repeatedly on the same inputs, you can just use the for var in some_range as a counter, without var changing the inputs to the function.\nYou could also\n\n# compute your differences here\n\nFinally, plot a histogram of the differences in means along with a vertical line showing the observed difference. You can adjust the code below based on what your named your vector of differences above. If you have questions about any of the arguments to histogram() or `vline!(), please experiment, ask, and/or look at the website’s Making Plots with Julia tutorial.\n\n\n\n\n\n\nMutating Functions\n\n\n\nFunctions which change their inputs in-place (without needing the output to be saved to another variable) are called mutating. In Julia, the convention is to end functions which mutate their inputs with an exclamation point !. For example, vline(...) will create a new plot with just a vertical line, but vline!(p, ...) will add a vertical line to the existing plot p. There are many mutating functions, particularly for plotting, that you will encounter, but it’s good practice in general to avoid mutation for your own functions.\n\n\n\n\n\n\n\n\nKeyword Arguments\n\n\n\nJulia separates arguments which are required and those which are optional (and therefore require keywords to tell the function that they’re not just the defaults) with a semi-colon, as you can see in the code below.\n\n\n\np = histogram(simulated_differences; # this is the vector for the histogram\nxlabel=\"Differences in Means\", # set the x-axis label\nylabel=\"Proportion of Samples\", # set the y-axis label\nlabel=\"Simulations Assuming Skeptical Hypothesis\", # set legend label for the data in this series,\nlegend=:topleft, # legend position; you can turn the legend off with legend=false\nnormalize=true, # plot proportion of samples instead of raw counts\ncolor=:blue # set the color of histogram bars\n)\nvline!(p, # plot on the previous plot p\n[observed_difference]; # vline wants the value(s) to be in a vector,\nlabel=\"Observed Difference\", # add line label to legend\nlinewidth=2, # set the width of this line\ncolor=:red # set the color of the line\n)\n\nLoadError: UndefVarError: simulated_differences not defined\n\n\n\n\nProblem 3: Interpret Results (5 Points)\nCongratulations, you just tested a hypothesis based on analyzing simulations! What do you think about the plausibility of the skeptic’s hypothesis that there is no difference? Feel free to use any quantitative or qualitative assessments of your simulations and the observed difference."
  },
  {
    "objectID": "labs/lab01/lab01.html#references-consulted",
    "href": "labs/lab01/lab01.html#references-consulted",
    "title": "Lab 1: Getting Started with Julia",
    "section": "References Consulted",
    "text": "References Consulted"
  },
  {
    "objectID": "tutorials/turing-mcmc.html",
    "href": "tutorials/turing-mcmc.html",
    "title": "Markov Chain Monte Carlo With Turing",
    "section": "",
    "text": "This tutorial will give some examples of using Turing.jl and Markov Chain Monte Carlo to sample from posterior distributions."
  },
  {
    "objectID": "tutorials/turing-mcmc.html#overview",
    "href": "tutorials/turing-mcmc.html#overview",
    "title": "Markov Chain Monte Carlo With Turing",
    "section": "",
    "text": "This tutorial will give some examples of using Turing.jl and Markov Chain Monte Carlo to sample from posterior distributions."
  },
  {
    "objectID": "tutorials/turing-mcmc.html#setup",
    "href": "tutorials/turing-mcmc.html#setup",
    "title": "Markov Chain Monte Carlo With Turing",
    "section": "Setup",
    "text": "Setup\n\nusing Turing\nusing Distributions\nusing Plots\ndefault(fmt = :png) # the tide gauge data is long, this keeps images a manageable size\nusing LaTeXStrings\nusing StatsPlots\nusing Measures\nusing StatsBase\nusing Optim\nusing Random\nusing DataFrames\nusing DataFramesMeta\nusing Dates\nusing CSV\n\nAs this tutorial involves random number generation, we will set a random seed to ensure reproducibility.\n\nRandom.seed!(1);"
  },
  {
    "objectID": "tutorials/turing-mcmc.html#fitting-a-linear-regression-model",
    "href": "tutorials/turing-mcmc.html#fitting-a-linear-regression-model",
    "title": "Markov Chain Monte Carlo With Turing",
    "section": "Fitting A Linear Regression Model",
    "text": "Fitting A Linear Regression Model\nLet’s start with a simple example: fitting a linear regression model to simulated data.\n\n\n\n\n\n\nPositive Control Tests\n\n\n\nSimulating data with a known data-generating process and then trying to obtain the parameters for that process is an important step in any workflow.\n\n\n\nSimulating Data\nThe data-generating process for this example will be: \\[\n\\begin{gather}\ny = 5 + 2x + \\varepsilon \\\\\n\\varepsilon \\sim \\text{Normal}(0, 3),\n\\end{gather}\n\\] where \\(\\varepsilon\\) is so-called “white noise”, which adds stochasticity to the data set. The generated dataset is shown in Figure 1.\n\n\n\n\n\n\nFigure 1: Scatterplot of our generated data.\n\n\n\n\n\nModel Specification\nThe statistical model for a standard linear regression problem is \\[\n\\begin{gather}\ny = a + bx + \\varepsilon \\\\\n\\varepsilon \\sim \\text{Normal}(0, \\sigma).\n\\end{gather}\n\\]\nRearranging, we can rewrite the likelihood function as: \\[y \\sim \\text{Normal}(\\mu, \\sigma),\\] where \\(\\mu = a + bx\\). This means that we have three parameters to fit: \\(a\\), \\(b\\), and \\(\\sigma^2\\).\nNext, we need to select priors on our parameters. We’ll use relatively generic distributions to avoid using the information we have (since we generated the data ourselves), but in practice, we’d want to use any relevant information that we had from our knowledge of the problem. Let’s use relatively diffuse normal distributions for the trend parameters \\(a\\) and \\(b\\) and a half-normal distribution (a normal distribution truncated at 0, to only allow positive values) for the variance \\(\\sigma^2\\), as recommended by Gelman (2006).\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Anal., 1(3), 515–533. https://doi.org/10.1214/06-BA117A\n\\[\n\\begin{gather}\na \\sim \\text{Normal(0, 10)} \\\\\nb \\sim \\text{Normal(0, 10)} \\\\\n\\sigma \\sim \\text{Half-Normal}(0, 25)\n\\end{gather}\n\\]\n\n\nUsing Turing\n\nCoding the Model\nTuring.jl uses the @model macro to specify the model function. We’ll follow the setup in the Turing documentation.\nTo specify distributions on parameters (and the data, which can be thought of as uncertain parameters in Bayesian statistics), use a tilde ~, and use equals = for transformations (which we don’t have in this case).\n\n@model function linear_regression(x, y)\n    # set priors\n1    σ ~ truncated(Normal(0, 25); lower=0)\n2    a ~ Normal(0, 10)\n    b ~ Normal(0, 10)\n\n    # compute the likelihood\n3    for i = 1:length(y)\n        # compute the mean value for the data point\n        μ = a + b * x[i]\n        y[i] ~ Normal(μ, σ)\n    end\nend\n\n\n1\n\nStandard deviations must be positive, so we use a normal distribution truncated at zero.\n\n2\n\nWe’ll keep these both relative uninformative to reflect a more “realistic” modeling scenario.\n\n3\n\nIn this case, we specify the likelihood with a loop. We could also rewrite this as a joint likelihood over all of the data using linear algebra, which might be more efficient for large and/or complex models or datasets, but the loop is more readable in this simple case.\n\n\n\n\nlinear_regression (generic function with 2 methods)\n\n\n\n\nFitting The Model\nNow we can call the sampler to draw from the posterior. We’ll use the No-U-Turn sampler (Hoffman & Gelman, 2014), which is a Hamiltonian Monte Carlo algorithm (a different category of MCMC sampler than the Metropolis-Hastings algorithm discussed in class). We’ll also use 4 chains so we can test that the chains are well-mixed, and each chain will be run for 5,000 iterations11 Hamiltonian Monte Carlo samplers often need to be run for fewer iterations than Metropolis-Hastings samplers, as the exploratory step uses information about the gradient of the statistical model, versus the random walk of Metropolis-Hastings. The disadvantage is that this gradient information must be available, which is not always the case for external simulation models. Simulation models coded in Julia can usually be automatically differentiated by Turing’s tools, however.\n\nHoffman, M. D., & Gelman, A. (2014). The No-U-Turn sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res., 15(47), 1593–1623.\n\n# set up the sampler\n1model = linear_regression(x, y)\n2n_chains = 4\n3n_per_chain = 5000\n4chain = sample(model, NUTS(), MCMCThreads(), n_per_chain, n_chains, drop_warmup=true)\n5@show chain\n\n\n1\n\nInitialize the model with the data.\n\n2\n\nWe use multiple chains to help diagnose convergence.\n\n3\n\nThis sets the number of iterations for each chain.\n\n4\n\nSample from the posterior using NUTS and drop the iterations used to warmup the sampler. The MCMCThreads() call tells the sampler to use available processor threads for the multiple chains, but it will just sample them in serial if only one thread exists.\n\n5\n\nThe @show macro makes the display of the output a bit cleaner.\n\n\n\n\n┌ Warning: Only a single thread available: MCMC chains are not sampled in parallel\n└ @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/sample.jl:296\n\n\n┌ Info: Found initial step size\n└   ϵ = 0.00625\n┌ Info: Found initial step size\n└   ϵ = 0.025\n\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n┌ Info: Found initial step size\n└   ϵ = 0.003125\n\n\nSampling (1 threads):  50%|██████████████▌              |  ETA: 0:00:01\n\n\nSampling (1 threads): 100%|█████████████████████████████| Time: 0:00:02\n\n\nchain = MCMC chain (5000×15×4 Array{Float64, 3})\n\n\n\nChains MCMC chain (5000×15×4 Array{Float64, 3}):\nIterations        = 1001:1:6000\nNumber of chains  = 4\nSamples per chain = 5000\nWall duration     = 20.05 seconds\nCompute duration  = 17.25 seconds\nparameters        = σ, a, b\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\nSummary Statistics\n  parameters      mean       std      mcse     ess_bulk     ess_tail      rhat ⋯\n      Symbol   Float64   Float64   Float64      Float64      Float64   Float64 ⋯\n           σ    5.3881    0.9886    0.0097   10835.5758   10595.6871    1.0003 ⋯\n           a    7.3483    2.1028    0.0231    8360.9948    8903.0798    1.0002 ⋯\n           b    1.7993    0.1865    0.0021    8290.7784    8803.3686    1.0003 ⋯\n                                                                1 column omitted\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n           σ    3.8905    4.6873    5.2471    5.9322    7.7226\n           a    3.1190    5.9784    7.3761    8.7487   11.4444\n           b    1.4350    1.6773    1.7968    1.9214    2.1732\n\n\n\n\nHow can we interpret the output? The first parts of the summary statistics are straightforward: we get the mean, standard deviation, and Monte Carlo standard error (mcse) of each parameter. We also get information about the effective sample size (ESS)2 and \\(\\hat{R}\\), which measures the ratio of within-chain variance and across-chain variance as a check for convergence3.2 The ESS reflects the efficiency of the sampler: this is an estimate of the equivalent number of independent samples; the more correlated the samples, the lower the ESS.3 The closer \\(\\hat{R}\\) is to 1, the better.\nIn this case, we can see that we were generally able to recover the “true” data-generating values of \\(\\sigma = 4\\) and \\(b = 2\\), but \\(a\\) is slightly off (the mean is 3, rather than the data-generating value of 5). In fact, there is substantial uncertainty about \\(a\\), with a 95% credible interval of \\((3.1, 11.4)\\) (compared to \\((1.4, 2.2)\\) for \\(b\\)). This isn’t surprising: given the variance of the noise \\(\\sigma^2\\), there are many different intercepts which could fit within that spread.\nLet’s now plot the chains for visual inspection.\n\nplot(chain)\n\n\n\n\nFigure 2: Output from the MCMC sampler. Each row corresponds to a different parameter: \\(\\sigma\\), \\(a\\), and \\(b\\). Each chain is shown in a different color. The left column shows the sampler traceplots, and the right column the resulting posterior distributions.\n\n\n\n\nWe can see from Figure 2 that our chains mixed well and seem to have converged to similar distributions! The traceplots have a “hairy caterpiller” appearance, suggesting relatively little autocorrelation. We can also see how much more uncertainty there is with the intercept \\(a\\), while the slope \\(b\\) is much more constrained.\nAnother interesting comparison we can make is with the maximum-likelihood estimate (MLE), which we can obtain through optimization.\n\nmle_model = linear_regression(x, y)\n1mle = optimize(mle_model, MLE())\ncoef(mle)\n\n\n1\n\nThis is where we use the Optim.jl package in this tutorial.\n\n\n\n\n\n3-element Named Vector{Float64}\nA  │ \n───┼────────\nσ  │ 4.75545\na  │ 7.65636\nb  │ 1.77736\n\nWe could also get the maximum a posteriori (MAP) estimate, which includes the prior density, by replacing MLE() with MAP().\n\n\n\nModel Diagnostics and Posterior Predictive Checks\nOne advantage of the Bayesian modeling approach here is that we have access to a generative model, or a model which we can use to generate datasets. This means that we can now use Monte Carlo simulation, sampling from our posteriors, to look at how uncertainty in the parameter estimates propagates through the model. Let’s write a function which gets samples from the MCMC chains and generates datasets.\n\nfunction mc_predict_regression(x, chain)\n    # get the posterior samples\n1    a = Array(group(chain, :a))\n    b = Array(group(chain, :b))\n    σ = Array(group(chain, :σ))\n\n    # loop and generate alternative realizations\n    μ = a' .+ x * b'\n    y = zeros((length(x), length(a)))\n    for i = 1:length(a)\n        y[:, i] = rand.(Normal.(μ[:, i], σ[i]))\n    end\n    return y\nend\n\n\n1\n\nThe Array(group()) syntax is more general than we need, but is useful if we have multiple variables which were sampled as a group, for example multiple regression coefficients. Otherwise, we can just use e.g. Array(chain, :a).\n\n\n\n\nmc_predict_regression (generic function with 1 method)\n\n\nNow we can generate a predictive interval and median and compare to the data.\n\nx_pred = 0:20\ny_pred = mc_predict_regression(x_pred, chain)\n\n21×20000 Matrix{Float64}:\n -0.440341  14.2143    3.73736    3.98402  …  13.9896   12.1475    5.46884\n -7.87522    4.36333  -7.19389    3.34537      9.48413  11.4606    3.81313\n 17.3151     8.9222    0.292523  12.9925       7.6094   11.5593   10.3064\n  2.28767    7.4078    9.09122    9.90026     21.4866   21.4643    4.38994\n 23.1321     9.28746   9.56973   17.9069      14.6245    6.80164  23.3068\n 10.0429    12.6741   23.6552    24.0107   …  17.07     12.9291   19.7511\n 23.3753    33.5452   11.6653    14.3672      21.4006   24.598    25.4434\n 11.6998     7.79426  16.9991    17.8128       8.01083  19.9234   17.2112\n 16.3753    22.476    20.8614    20.1019      15.169    22.8508   21.7635\n 17.1411    14.5313   32.2826    23.3866      27.5636   22.508    19.5266\n 27.7594    28.5052   30.7478    35.5763   …  22.858    27.8321   17.396\n 28.2636    24.2078   23.8358    27.5576      23.1143   30.4325   25.8818\n 35.3991    39.3917   40.5648    30.0351      29.1015   31.9592   38.7204\n 27.9246    34.618    30.7003    31.2341      20.0888   18.9489   24.3442\n 44.3301    21.7205   26.0331    34.8189      34.9326   26.6271   37.492\n 29.0048    45.0313   38.5674    34.2622   …  38.0261   42.037    26.6537\n 38.1531    35.6617   28.2519    36.4022      42.352    38.8477   38.4148\n 41.646     26.0779   38.9314    42.054       30.3764   37.7851   40.6086\n 38.4945    51.9845   42.9168    42.3723      37.3804   47.7923   38.3248\n 37.3901    44.5299   44.5209    46.5456      35.1081   43.7139   47.2316\n 55.3581    41.1191   45.0658    35.4023   …  40.9341   35.7394   36.0986\n\n\nNotice the dimension of y_pred: we have 20,000 columns, because we have 4 chains with 5,000 samples each. If we had wanted to subsample (which might be necessary if we had hundreds of thousands or millions of samples), we could have done that within mc_linear_regression before simulation.\n\n# get the boundaries for the 95% prediction interval and the median\ny_ci_low = quantile.(eachrow(y_pred), 0.025)\ny_ci_hi = quantile.(eachrow(y_pred), 0.975)\ny_med = quantile.(eachrow(y_pred), 0.5)\n\nNow, let’s plot the prediction interval and median, and compare to the original data.\n\n# plot prediction interval\n1plot(x_pred, y_ci_low, fillrange=y_ci_hi, xlabel=L\"$x$\", ylabel=L\"$y$\", fillalpha=0.3, fillcolor=:blue, label=\"95% Prediction Interval\", legend=:topleft, linealpha=0)\n2plot!(x_pred, y_med, color=:blue, label=\"Prediction Median\")\n3scatter!(x, y, color=:red, label=\"Data\")\n\n\n1\n\nPlot the 95% posterior prediction interval as a shaded blue ribbon.\n\n2\n\nPlot the posterior prediction median as a blue line.\n\n3\n\nPlot the data as discrete red points.\n\n\n\n\n\n\n\nFigure 3: Posterior 95% predictive interval and median for the linear regression model. The data is plotted in red for comparison.\n\n\n\n\nFrom Figure 3, it looks like our model might be slightly under-confident, as with 20 data points, we would expect 5% of them (or 1 data point) to be outside the 95% prediction interval. It’s hard to tell with only 20 data points, though! We could resolve this by tightening our priors, but this depends on how much information we used to specify them in the first place. The goal shouldn’t be to hit a specific level of uncertainty, but if there is a sound reason to tighten the priors, we could do so.\nNow let’s look at the residuals from the posterior median and the data. The partial autocorrelations plotted in Figure 4 are not fully convincing, as there are large autocorrelation coefficients with long lags, but the dataset is quite small, so it’s hard to draw strong conclusions. We won’t go further down this rabbit hole as we know our data-generating process involved independent noise, but for a real dataset, we might want to try a model specification with autocorrelated errors to compare.\n\n# calculate the median predictions and residuals\ny_pred_data = mc_predict_regression(x, chain)\ny_med_data = quantile.(eachrow(y_pred_data), 0.5)\nresiduals = y_med_data .- y\n\n# plot the residuals and a line to show the zero\nplot(pacf(residuals, 1:4), line=:stem, marker=:circle, legend=:false, grid=:false, linewidth=2, xlabel=\"Lag\", ylabel=\"Partial Autocorrelation\", markersize=8, tickfontsize=14, guidefontsize=16, legendfontsize=16)\nhline!([0], linestyle=:dot, color=:red)\n\n\n\n\n\nFigure 4: Partial autocorrelation function of model residuals, relative to the predictive median."
  },
  {
    "objectID": "tutorials/turing-mcmc.html#fitting-extreme-value-models-to-tide-gauge-data",
    "href": "tutorials/turing-mcmc.html#fitting-extreme-value-models-to-tide-gauge-data",
    "title": "Markov Chain Monte Carlo With Turing",
    "section": "Fitting Extreme Value Models to Tide Gauge Data",
    "text": "Fitting Extreme Value Models to Tide Gauge Data\nLet’s now look at an example of fitting an extreme value distribution (namely, a generalized extreme value distribution, or GEV) to tide gauge data. GEV distributions have three parameters:\n\n\\(\\mu\\), the location parameter, which reflects the positioning of the bulk of the GEV distribution;\n\\(\\sigma\\), the scale parameter, which reflects the width of the bulk;\n\\(\\xi\\), the shape parameter, which reflects the thickness and boundedness of the tail.\n\nThe shape parameter \\(\\xi\\) is often of interest, as there are three classes of GEV distributions corresponding to different signs:\n\n\\(\\xi &lt; 0\\) means that the distribution is bounded;\n\\(\\xi = 0\\) means that the distribution has a thinner tail, so the “extreme extremes” are less likely;\n\\(\\xi &gt; 0\\) means that the distribution has a thicker tail.\n\n\nLoad Data\nFirst, let’s load the data. We’ll use data from the University of Hawaii Sea Level Center (Caldwell et al., 2015) for San Francisco, from 1897-2013. If you don’t have this data and are working with the notebook, download it here. We’ll assume it’s in a data/ subdirectory, but change the path as needed.\n\nCaldwell, P. C., Merrifield, M. A., & Thompson, P. R. (2015). Sea level measured by tide gauges from global oceans — the joint archive for sea level holdings (NCEI accession 0019568). NOAA National Centers for Environmental Information (NCEI). https://doi.org/10.7289/V5V40S7W\nThe dataset consists of dates and hours and the tide-gauge measurement, in mm. We’ll load the dataset into a DataFrame.\n\nfunction load_data(fname)\n    date_format = DateFormat(\"yyyy-mm-dd HH:MM:SS\")\n1    df = @chain fname begin\n2        CSV.File(; delim=',', header=false)\n3        DataFrame\n4        rename(\"Column1\" =&gt; \"year\",\n                \"Column2\" =&gt; \"month\",\n                \"Column3\" =&gt; \"day\",\n                \"Column4\" =&gt; \"hour\",\n                \"Column5\" =&gt; \"gauge\")\n        # need to reformat the decimal date in the data file\n5        @transform :datetime = DateTime.(:year, :month, :day, :hour)\n        # replace -99999 with missing\n6        @transform :gauge = ifelse.(abs.(:gauge) .&gt;= 9999, missing, :gauge)\n7        select(:datetime, :gauge)\n    end\n    return df\nend\n\n\n1\n\nThis uses the DataFramesMeta.jl package, which makes it easy to string together commands to load and process data\n\n2\n\nLoad the file, assuming there is no header.\n\n3\n\nConvert to a DataFrame.\n\n4\n\nRename columns for ease of access.\n\n5\n\nReformat the decimal datetime provided in the file into a Julia DateTime.\n\n6\n\nReplace missing data with missing.\n\n7\n\nSelect only the :datetime and :gauge columns.\n\n\n\n\nload_data (generic function with 1 method)\n\n\n\ndat = load_data(\"data/h551a.csv\")\nfirst(dat, 6)\n\n\n6×2 DataFrame\n\n\nTable 1: Processed hourly tide gauge data from San Francisco, from 8/1/1897-1/31/2023.\n\n\nRow\ndatetime\ngauge\n\n\n\nDateTime\nInt64?\n\n\n\n\n1\n1897-08-01T08:00:00\n3292\n\n\n2\n1897-08-01T09:00:00\n3322\n\n\n3\n1897-08-01T10:00:00\n3139\n\n\n4\n1897-08-01T11:00:00\n2835\n\n\n5\n1897-08-01T12:00:00\n2377\n\n\n6\n1897-08-01T13:00:00\n2012\n\n\n\n\n\n\n\n1@df dat plot(:datetime, :gauge, label=\"Observations\", bottom_margin=9mm)\nxaxis!(\"Date\", xrot=30)\nyaxis!(\"Mean Water Level\")\n\n\n1\n\nThis uses the DataFrame plotting recipe with the @df macro from StatsPlots.jl. This is not needed (you could replace e.g. :datetime with dat.datetime), but it cleans things up slightly.\n\n\n\n\n\n\n\nFigure 5: Hourly mean water at the San Francisco tide gauge from 1897-2023.\n\n\n\n\nNext, we need to detrend the data to remove the impacts of sea-level rise. We do this by removing a one-year moving average, centered on the data point, per the recommendation of Arns et al. (2013).\n\n# calculate the moving average and subtract it off\nma_length = 366\nma_offset = Int(floor(ma_length/2))\nmoving_average(series,n) = [mean(@view series[i-n:i+n]) for i in n+1:length(series)-n]\ndat_ma = DataFrame(datetime=dat.datetime[ma_offset+1:end-ma_offset], residual=dat.gauge[ma_offset+1:end-ma_offset] .- moving_average(dat.gauge, ma_offset))\n\n# plot\n@df dat_ma plot(:datetime, :residual, label=\"Detrended Observations\", bottom_margin=9mm)\nxaxis!(\"Date\", xrot=30)\nyaxis!(\"Mean Water Level\")\n\n\n\n\nFigure 6: Mean water level from the San Francisco tide gauge, detrended using a 1-year moving average centered on the data point, per the recommendation of Arns et al. (2013).\nArns, A., Wahl, T., Haigh, I. D., Jensen, J., & Pattiaratchi, C. (2013). Estimating extreme water level probabilities: A comparison of the direct methods and recommendations for best practise. Coast. Eng., 81, 51–66. https://doi.org/10.1016/j.coastaleng.2013.07.003\n\n\n\n\n\nThe last step in preparing the data is to find the annual maxima. We can do this using the groupby, transform, and combine functions from DataFrames.jl, as below.\n\n# calculate the annual maxima\n1dat_ma = dropmissing(dat_ma)\n2dat_annmax = combine(dat_ma -&gt; dat_ma[argmax(dat_ma.residual), :],\n                groupby(transform(dat_ma, :datetime =&gt; x-&gt;year.(x)), :datetime_function))\n3delete!(dat_annmax, nrow(dat_annmax))\n\n# make a histogram of the maxima to see the distribution\nhistogram(dat_annmax.residual, label=false)\nylabel!(\"Count\")\nxlabel!(\"Mean Water Level (mm)\")\n\n\n1\n\nIf we don’t drop the values which are missing, they will affect the next call to argmax.\n\n2\n\nThis first groups the data based on the year (with groupby and using Dates.year() to get the year of each data point), then pulls the rows which correspond to the maxima for each year (using argmax).\n\n3\n\nThis will delete the last year, in this case 2023, because the dataset only goes until March 2023 and this data point is almost certainly an outlier due to the limited data from that year.\n\n\n\n\n\n\n\nFigure 7: Histogram of annual block maxima from 1898-2022 from the San Francisco tide gauge dataset.\n\n\n\n\n\n\nFit The Model\n\n@model function gev_annmax(y)               \n1    μ ~ Normal(1000, 100)\n2    σ ~ truncated(Normal(0, 100); lower=0)\n3    ξ ~ Normal(0, 0.5)\n\n4    y ~ GeneralizedExtremeValue(μ, σ, ξ)\nend\n\n5gev_model = gev_annmax(dat_annmax.residual)\n6n_chains = 4\n7n_per_chain = 5000\n8gev_chain = sample(gev_model, NUTS(), MCMCThreads(), n_per_chain, n_chains; drop_warmup=true)\n@show gev_chain\n\n\n1\n\nLocation parameter prior: We know that this is roughly on the 1000 mm order of magnitude, but want to keep this relatively broad.\n\n2\n\nScale parameter prior: This parameter must be positive, so we use a normal truncated at zero.\n\n3\n\nShape parameter prior: These are usually small and are hard to constrain, so we will use a more informative prior.\n\n4\n\nThe data is independently GEV-distributed as we’ve removed the long-term trend and are using long blocks.\n\n5\n\nInitialize the model.\n\n6\n\nWe use multiple chains to help diagnose convergence.\n\n7\n\nThis sets the number of iterations for each chain.\n\n8\n\nSample from the posterior using NUTS and drop the iterations used to warmup the sampler.\n\n\n\n\n┌ Warning: Only a single thread available: MCMC chains are not sampled in parallel\n└ @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/sample.jl:296\n\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n┌ Info: Found initial step size\n└   ϵ = 0.0125\n\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n┌ Info: Found initial step size\n└   ϵ = 0.2\n\n\nSampling (1 threads):  50%|██████████████▌              |  ETA: 0:00:04\n\n\nSampling (1 threads): 100%|█████████████████████████████| Time: 0:00:08\n\n\ngev_chain = MCMC chain (5000×15×4 Array{Float64, 3})\n\n\n\nChains MCMC chain (5000×15×4 Array{Float64, 3}):\nIterations        = 1001:1:6000\nNumber of chains  = 4\nSamples per chain = 5000\nWall duration     = 15.96 seconds\nCompute duration  = 15.51 seconds\nparameters        = μ, σ, ξ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\nSummary Statistics\n  parameters        mean       std      mcse     ess_bulk     ess_tail      rh ⋯\n      Symbol     Float64   Float64   Float64      Float64      Float64   Float ⋯\n           μ   1257.8174    5.6701    0.0513   12216.6653   12642.3312    1.00 ⋯\n           σ     57.1982    4.3214    0.0366   14201.5441   12575.6044    1.00 ⋯\n           ξ      0.0292    0.0625    0.0008    5915.1552    7463.8803    1.00 ⋯\n                                                               2 columns omitted\nQuantiles\n  parameters        2.5%       25.0%       50.0%       75.0%       97.5% \n      Symbol     Float64     Float64     Float64     Float64     Float64 \n           μ   1246.8628   1253.9821   1257.8132   1261.6027   1269.2078\n           σ     49.4284     54.1859     56.9353     59.9665     66.3174\n           ξ     -0.0811     -0.0151      0.0250      0.0699      0.1627\n\n\n\n\n\nplot(gev_chain)\n\n\n\n\nFigure 8: Traceplots (left) and marginal distributions (right) from the MCMC sampler for the GEV model.\n\n\n\n\nFrom Figure 8, it looks like all of the chains have converged to the same distribution; the Gelman-Rubin diagnostic is also close to 1 for all parameters. Next, we can look at a corner plot to see how the parameters are correlated.\n\ncorner(gev_chain)\n\n\n\n\nFigure 9: Corner plot for the GEV model.\n\n\n\n\nFigure 9 suggests that the location and scale parameters \\(\\mu\\) and \\(\\sigma\\) are positively correlated. This makes some intuitive sense, as increasing the location parameter shifts the bulk of the distribution in a positive direction, and the increasing scale parameter then increases the likelihood of lower values. However, if these parameters are increased, the shape parameter \\(\\xi\\) decreases, as the tail of the GEV does not need to be as thick due to the increased proximity of outliers to the bulk."
  },
  {
    "objectID": "tutorials/julia-plots.html",
    "href": "tutorials/julia-plots.html",
    "title": "Tutorial: Making Plots with Julia",
    "section": "",
    "text": "This tutorial will give some examples of plotting and plotting features in Julia, as well as providing references to some relevant resources. The main plotting library is Plots.jl, but there are some others that provide useful features."
  },
  {
    "objectID": "tutorials/julia-plots.html#overview",
    "href": "tutorials/julia-plots.html#overview",
    "title": "Tutorial: Making Plots with Julia",
    "section": "",
    "text": "This tutorial will give some examples of plotting and plotting features in Julia, as well as providing references to some relevant resources. The main plotting library is Plots.jl, but there are some others that provide useful features."
  },
  {
    "objectID": "tutorials/julia-plots.html#some-resources",
    "href": "tutorials/julia-plots.html#some-resources",
    "title": "Tutorial: Making Plots with Julia",
    "section": "Some Resources",
    "text": "Some Resources\n\nPlots.jl useful tips\nPlots.jl examples\nPlot attributes\nAxis attributes\nColor names"
  },
  {
    "objectID": "tutorials/julia-plots.html#demos",
    "href": "tutorials/julia-plots.html#demos",
    "title": "Tutorial: Making Plots with Julia",
    "section": "Demos",
    "text": "Demos\n\nusing Plots\nusing Random\nRandom.seed!(1);\n\n\nLine Plots\nTo generate a basic line plot, use plot.\n\ny = rand(5)\nplot(y, label=\"original data\", legend=:topright)\n\n\n\n\nThere’s a lot of customization here that can occur, a lot of which is discussed in the docs or can be found with some Googling.\n\n\nAdding Plot Elements\nNow we can add some other lines and point markers.\n\ny2 = rand(5)\ny3 = rand(5)\nplot!(y2, label=\"new data\")\nscatter!(y3, label=\"even more data\")\n\n\n\n\nRemember that an exclamation mark (!) at the end of a function name means that function modifies an object in-place, so plot! and scatter! modify the current plotting object, they don’t create a new plot.\n\n\nRemoving Plot Elements\nSometimes we want to remove legends, axes, grid lines, and ticks.\n\nplot!(legend=false, axis=false, grid=false, ticks=false)\n\n\n\n\n\n\nAspect Ratio\nIf we want to have a square aspect ratio, use ratio = 1.\n\nv = rand(5)\nplot(v, ratio=1, legend=false)\nscatter!(v)\n\n\n\n\n\n\nHeatmaps\nA heatmap is effectively a plotted matrix with colors chosen according to the values. Use clim to specify a fixed range for the color limits.\n\nA = rand(10, 10)\nheatmap(A, clim=(0, 1), ratio=1, legend=false, axis=false, ticks=false)\n\n\n\n\n\nM = [ 0 1 0; 0 0 0; 1 0 0]\nwhiteblack = [RGBA(1,1,1,0), RGB(0,0,0)]\nheatmap(c=whiteblack, M, aspect_ratio = 1, ticks=.5:3.5, lims=(.5,3.5), gridalpha=1, legend=false, axis=false, ylabel=\"i\", xlabel=\"j\")\n\n\n\n\n\nCustom Colors\n\nusing Colors\n\nmycolors = [colorant\"lightslateblue\",colorant\"limegreen\",colorant\"red\"]\nA = [i for i=50:300, j=1:100]\nheatmap(A, c=mycolors, clim=(1,300))\n\n\n\n\n\n\n\nPlotting Areas Under Curves\n\ny = rand(10)\nplot(y, fillrange= y.*0 .+ .5, label= \"above/below 1/2\", legend =:top)\n\n\n\n\n\nx = LinRange(0,2,100)\ny1 = exp.(x)\ny2 = exp.(1.3 .* x)\nplot(x, y1, fillrange = y2, fillalpha = 0.35, c = 1, label = \"Confidence band\", legend = :topleft)\n\n\n\n\n\nx = -3:.01:3\nareaplot(x, exp.(-x.^2/2)/√(2π),alpha=.25,legend=false)\n\n\n\n\n\nM = [1 2 3; 7 8 9; 4 5 6; 0 .5 1.5]\nareaplot(1:3, M, seriescolor = [:red :green :blue ], fillalpha = [0.2 0.3 0.4])\n\n\n\n\n\nusing SpecialFunctions\nf = x-&gt;exp(-x^2/2)/√(2π)\nδ = .01\nplot()\nx = √2 .* erfinv.(2 .*(δ/2 : δ : 1) .- 1)\nareaplot(x, f.(x), seriescolor=[ :red,:blue], legend=false)\nplot!(x, f.(x),c=:black)\n\n\n\n\n\n\nPlotting Shapes\n\nrectangle(w, h, x, y) = Shape(x .+ [0,w,w,0], y .+ [0,0,h,h])\ncircle(r,x,y) = (θ = LinRange(0,2π,500); (x.+r.*cos.(θ), y.+r.*sin.(θ)))\nplot(circle(5,0,0), ratio=1, c=:red, fill=true)\nplot!(rectangle(5*√2,5*√2,-2.5*√2,-2.5*√2),c=:white,fill=true,legend=false)\n\n\n\n\n\n\nPlotting Distributions\nThe StatsPlots.jl package is very useful for making various plots of probability distributions.\n\nusing Distributions, StatsPlots\nplot(Normal(2, 5))\n\n\n\n\n\nscatter(LogNormal(0.8, 1.5))\n\n\n\n\nWe can also use this functionality to plot distributions of data in tabular data structures like DataFrames.\n\nusing DataFrames\ndat = DataFrame(a = 1:10, b = 10 .+ rand(10), c = 10 .* rand(10))\n@df dat density([:b :c], color=[:black :red])\n\n\n\n\n\n\nEditing Plots Manually\n\npl = plot(1:4,[1, 4, 9, 16])\n\n\n\n\n\npl.attr\n\nRecipesPipeline.DefaultsDict with 30 entries:\n  :dpi                      =&gt; 96\n  :background_color_outside =&gt; :match\n  :plot_titlefontvalign     =&gt; :vcenter\n  :warn_on_unsupported      =&gt; true\n  :background_color         =&gt; RGBA{Float64}(1.0,1.0,1.0,1.0)\n  :size                     =&gt; (672, 480)\n  :inset_subplots           =&gt; nothing\n  :display_type             =&gt; :auto\n  :overwrite_figure         =&gt; true\n  :html_output_format       =&gt; :svg\n  :plot_titlefontfamily     =&gt; :match\n  :plot_titleindex          =&gt; 0\n  :foreground_color         =&gt; RGB{N0f8}(0.0,0.0,0.0)\n  :window_title             =&gt; \"Plots.jl\"\n  :plot_titlefontrotation   =&gt; 0.0\n  :extra_plot_kwargs        =&gt; Dict{Any, Any}()\n  :plot_titlefonthalign     =&gt; :hcenter\n  :pos                      =&gt; (0, 0)\n  :tex_output_standalone    =&gt; false\n  :extra_kwargs             =&gt; :series\n  :layout                   =&gt; 1\n  :thickness_scaling        =&gt; 1\n  :plot_titlelocation       =&gt; :center\n  :plot_titlefontsize       =&gt; 16\n  :plot_title               =&gt; \"\"\n  ⋮                         =&gt; ⋮\n\n\n\npl.series_list[1]\n\nPlots.Series(RecipesPipeline.DefaultsDict(:plot_object =&gt; Plot{Plots.GRBackend() n=1}, :subplot =&gt; Subplot{1}, :label =&gt; \"y1\", :fillalpha =&gt; nothing, :linealpha =&gt; nothing, :linecolor =&gt; RGBA{Float64}(0.0,0.6056031611752245,0.9786801175696073,1.0), :x_extrema =&gt; (NaN, NaN), :series_index =&gt; 1, :markerstrokealpha =&gt; nothing, :markeralpha =&gt; nothing…))\n\n\n\npl[:size]=(300,200)\n\n(300, 200)\n\n\n\npl\n\n\n\n\n\n\nLog-Scaled Axes\n\nxx = .1:.1:10\nplot(xx.^2, xaxis=:log, yaxis=:log)\n\n\n\n\n\nplot(exp.(x), yaxis=:log)"
  },
  {
    "objectID": "tutorials/julia-basics.html",
    "href": "tutorials/julia-basics.html",
    "title": "Tutorial: Julia Basics",
    "section": "",
    "text": "This tutorial will give some examples of basic Julia commands and syntax."
  },
  {
    "objectID": "tutorials/julia-basics.html#overview",
    "href": "tutorials/julia-basics.html#overview",
    "title": "Tutorial: Julia Basics",
    "section": "",
    "text": "This tutorial will give some examples of basic Julia commands and syntax."
  },
  {
    "objectID": "tutorials/julia-basics.html#getting-help",
    "href": "tutorials/julia-basics.html#getting-help",
    "title": "Tutorial: Julia Basics",
    "section": "Getting Help",
    "text": "Getting Help\n\nCheck out the official documentation for Julia: https://docs.julialang.org/en/v1/.\nStack Overflow is a commonly-used resource for programming assistance.\nAt a code prompt or in the REPL, you can always type ?functionname to get help."
  },
  {
    "objectID": "tutorials/julia-basics.html#comments",
    "href": "tutorials/julia-basics.html#comments",
    "title": "Tutorial: Julia Basics",
    "section": "Comments",
    "text": "Comments\nComments hide statements from the interpreter or compiler. It’s a good idea to liberally comment your code so readers (including yourself!) know why your code is structured and written the way it is. Single-line comments in Julia are preceded with a #. Multi-line comments are preceded with #= and ended with =#"
  },
  {
    "objectID": "tutorials/julia-basics.html#suppressing-output",
    "href": "tutorials/julia-basics.html#suppressing-output",
    "title": "Tutorial: Julia Basics",
    "section": "Suppressing Output",
    "text": "Suppressing Output\nYou can suppress output using a semi-colon (;).\n\n4+8;\n\nThat didn’t show anything, as opposed to:\n\n4+8\n\n12"
  },
  {
    "objectID": "tutorials/julia-basics.html#variables",
    "href": "tutorials/julia-basics.html#variables",
    "title": "Tutorial: Julia Basics",
    "section": "Variables",
    "text": "Variables\nVariables are names which correspond to some type of object. These names are bound to objects (and hence their values) using the = operator.\n\nx = 5\n\n5\n\n\nVariables can be manipulated with standard arithmetic operators.\n\n4 + x\n\n9\n\n\nAnother advantage of Julia is the ability to use Greek letters (or other Unicode characters) as variable names. For example, type a backslash followed by the name of the Greek letter (i.e. \\alpha) followed by TAB.\n\nα = 3\n\n3\n\n\nYou can also include subscripts or superscripts in variable names using \\_ and \\^, respectively, followed by TAB. If using a Greek letter followed by a sub- or super-script, make sure you TAB following the name of the letter before the sub- or super-script. Effectively, TAB after you finish typing the name of each \\character.\n\nβ₁ = 10 # The name of this variable was entered with \\beta + TAB + \\_1 + TAB\n\n10\n\n\nHowever, try not to overwrite predefined names! For example, you might not want to use π as a variable name…\n\nπ\n\nπ = 3.1415926535897...\n\n\nIn the grand scheme of things, overwriting π is not a huge deal unless you want to do some trigonometry. However, there are more important predefined functions and variables that you may want to be aware of. Always check that a variable or function name is not predefined!"
  },
  {
    "objectID": "tutorials/julia-basics.html#data-types",
    "href": "tutorials/julia-basics.html#data-types",
    "title": "Tutorial: Julia Basics",
    "section": "Data Types",
    "text": "Data Types\nEach datum (importantly, not the variable which is bound to it) has a data type. Julia types are similar to C types, in that they require not only the type of data (Int, Float, String, etc), but also the precision (which is related to the amount of memory allocated to the variable). Issues with precision won’t be a big deal in this class, though they matter when you’re concerned about performance vs. decimal accuracy of code.\nYou can identify the type of a variable or expression with the typeof() function.\n\ntypeof(\"This is a string.\")\n\nString\n\n\n\ntypeof(x)\n\nInt64\n\n\n\nNumeric types\nA key distinction is between an integer type (or Int) and a floating-point number type (or float). Integers only hold whole numbers, while floating-point numbers correspond to numbers with fractional (or decimal) parts. For example, 9 is an integer, while 9.25 is a floating point number. The difference between the two has to do with the way the number is stored in memory. 9, an integer, is handled differently in memory than 9.0, which is a floating-point number, even though they’re mathematically the same value.\n\ntypeof(9)\n\nInt64\n\n\n\ntypeof(9.25)\n\nFloat64\n\n\nSometimes certain function specifications will require you to use a Float variable instead of an Int. One way to force an Int variable to be a Float is to add a decimal point at the end of the integer.\n\ntypeof(9.)\n\nFloat64\n\n\n\n\nStrings\nStrings hold characters, rather than numeric values. Even if a string contains what seems like a number, it is actually stored as the character representation of the digits. As a result, you cannot use arithmetic operators (for example) on this datum.\n\n\"5\" + 5\n\nLoadError: MethodError: no method matching +(::String, ::Int64)\n\u001b[0mClosest candidates are:\n\u001b[0m  +(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m) at operators.jl:591\n\u001b[0m  +(\u001b[91m::T\u001b[39m, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:87\n\u001b[0m  +(\u001b[91m::T\u001b[39m, ::Integer) where T&lt;:AbstractChar at char.jl:237\n\u001b[0m  ...\n\n\nHowever, you can try to tell Julia to interpret a string encoding a numeric character as a numeric value using the parse() function. This can also be used to encode a numeric data as a string.\n\nparse(Int64, \"5\") + 5\n\n10\n\n\nTwo strings can be concatenated using *:\n\n\"Hello\" * \" \" * \"there\"\n\n\"Hello there\"\n\n\n\n\nBooleans\nBoolean variables (or Bools) are logical variables, that can have true or false as values.\n\nb = true\n\ntrue\n\n\nNumerical comparisons, such as ==, !=, or &lt;, return a Bool.\n\nc = 9 &gt; 11\n\nfalse\n\n\nBools are important for logical flows, such as if-then-else blocks or certain types of loops."
  },
  {
    "objectID": "tutorials/julia-basics.html#mathematical-operations",
    "href": "tutorials/julia-basics.html#mathematical-operations",
    "title": "Tutorial: Julia Basics",
    "section": "Mathematical operations",
    "text": "Mathematical operations\nAddition, subtraction, multiplication, and division work as you would expect. Just pay attention to types! The type of the output is influenced by the type of the inputs: adding or multiplying an Int by a Float will always result in a Float, even if the Float is mathematically an integer. Division is a little special: dividing an Int by another Int will still return a float, because Julia doesn’t know ahead of time if the denominator is a factor of the numerator.\n\n3 + 5\n\n8\n\n\n\n3 * 2\n\n6\n\n\n\n3 * 2.\n\n6.0\n\n\n\n6 - 2\n\n4\n\n\n\n9 / 3\n\n3.0\n\n\nRaising a base to an exponent uses ^, not **.\n\n3^2\n\n9\n\n\nJulia allows the use of updating operators to simplify updating a variable in place (in other words, using x += 5 instead of x = x + 5.\n\nBoolean algebra\nLogical operations can be used on variables of type Bool. Typical operators are && (and), || (or), and ! (not).\n\ntrue && true\n\ntrue\n\n\n\ntrue && false\n\nfalse\n\n\n\ntrue || false\n\ntrue\n\n\n\n!true\n\nfalse\n\n\nComparisons can be chained together.\n\n3 &lt; 4 || 8 == 12\n\ntrue\n\n\nWe didn’t do this above, since Julia doesn’t require it, but it’s easier to understand these types of compound expressions if you use parentheses to signal the order of operations. This helps with debugging!\n\n(3 &lt; 4) || (8 == 12)\n\ntrue"
  },
  {
    "objectID": "tutorials/julia-basics.html#data-structures",
    "href": "tutorials/julia-basics.html#data-structures",
    "title": "Tutorial: Julia Basics",
    "section": "Data Structures",
    "text": "Data Structures\nData structures are containers which hold multiple values in a convenient fashion. Julia has several built-in data structures, and there are many extensions provided in additional packages.\n\nTuples\nTuples are collections of values. Julia will pay attention to the types of these values, but they can be mixed. Tuples are also immutable: their values cannot be changed once they are defined.\nTuples can be defined by just separating values with commas.\n\ntest_tuple = 4, 5, 6\n\n(4, 5, 6)\n\n\nTo access a value, use square brackets and the desired index. Note: Julia indexing starts at 1, not 0!\n\ntest_tuple[1]\n\n4\n\n\nAs mentioned above, tuples are immutable. What happens if we try to change the value of the first element of test_tuple?\n\ntest_tuple[1] = 5\n\nLoadError: MethodError: no method matching setindex!(::Tuple{Int64, Int64, Int64}, ::Int64, ::Int64)\n\n\nTuples also do not have to hold the same types of values.\n\ntest_tuple_2 = 4, 5., 'h'\ntypeof(test_tuple_2)\n\nTuple{Int64, Float64, Char}\n\n\nTuples can also be defined by enclosing the values in parentheses.\ntest_tuple_3 = (4, 5., 'h')\ntypeof(test_tuple_3)\n\n\nArrays\nArrays also hold multiple values, which can be accessed based on their index position. Arrays are commonly defined using square brackets.\n\ntest_array = [1, 4, 7, 8]\ntest_array[2]\n\n4\n\n\nUnlike tuples, arrays are mutable, and their contained values can be changed later.\n\ntest_array[1] = 6\ntest_array\n\n4-element Vector{Int64}:\n 6\n 4\n 7\n 8\n\n\nArrays also can hold multiple types. Unlike tuples, this causes the array to no longer care about types at all.\n\ntest_array_2 = [6, 5., 'h']\ntypeof(test_array_2)\n\n\nVector{Any} (alias for Array{Any, 1})\n\n\n\nCompare this with test_array:\n\ntypeof(test_array)\n\n\nVector{Int64} (alias for Array{Int64, 1})\n\n\n\n\n\nDictionaries\nInstead of using integer indices based on position, dictionaries are indexed by keys. They are specified by passing key-value pairs to the Dict() method.\n\ntest_dict = Dict(\"A\"=&gt;1, \"B\"=&gt;2)\ntest_dict[\"B\"]\n\n2\n\n\n\n\nComprehensions\nCreating a data structure with more than a handful of elements can be tedious to do by hand. If your desired array follows a certain pattern, you can create structures using a comprehension. Comprehensions iterate over some other data structure (such as an array) implicitly and populate the new data structure based on the specified instructions.\n\n[i^2 for i in 0:1:5]\n\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25\n\n\nFor dictionaries, make sure that you also specify the keys.\n\nDict(string(i) =&gt; i^2 for i in 0:1:5)\n\nDict{String, Int64} with 6 entries:\n  \"4\" =&gt; 16\n  \"1\" =&gt; 1\n  \"5\" =&gt; 25\n  \"0\" =&gt; 0\n  \"2\" =&gt; 4\n  \"3\" =&gt; 9"
  },
  {
    "objectID": "tutorials/julia-basics.html#functions",
    "href": "tutorials/julia-basics.html#functions",
    "title": "Tutorial: Julia Basics",
    "section": "Functions",
    "text": "Functions\nA function is an object which accepts a tuple of arguments and maps them to a return value. In Julia, functions are defined using the following syntax.\n\nfunction my_actual_function(x, y)\n    return x + y\nend\nmy_actual_function(3, 5)\n\n8\n\n\nFunctions in Julia do not require explicit use of a return statement. They will return the last expression evaluated in their definition. However, it’s good style to explicitly return function outputs. This improves readability and debugging, especially when functions can return multiple expressions based on logical control flows (if-then-else blocks).\nFunctions in Julia are objects, and can be treated like other objects. They can be assigned to new variables or passed as arguments to other functions.\n\ng = my_actual_function\ng(3, 5)\n\n8\n\n\n\nfunction function_of_functions(f, x, y)\n    return f(x, y)\nend\nfunction_of_functions(g, 3, 5)\n\n8\n\n\n\nShort and Anonymous Functions\nIn addition to the long form of the function definition shown above, simple functions can be specified in more compact forms when helpful.\nThis is the short form:\n\nh₁(x) = x^2 # make the subscript using \\_1 + &lt;TAB&gt;\nh₁(4)\n\n16\n\n\nThis is the anonymous form:\n\nx-&gt;sin(x)\n(x-&gt;sin(x))(π/4)\n\n0.7071067811865475\n\n\n\n\nMutating Functions\nThe convention in Julia is that functions should not modify (or mutate) their input data. The reason for this is to ensure that the data is preserved. Mutating functions are mainly appropriate for applications where performance needs to be optimized, and making a copy of the input data would be too memory-intensive.\nIf you do write a mutating function in Julia, the convention is to add a ! to its name, like my_mutating_function!(x).\n\n\nOptional arguments\nThere are two extremes with regard to function parameters which do not always need to be changed. The first is to hard-code them into the function body, which has a clear downside: when you do want to change them, the function needs to be edited directly. The other extreme is to treat them as regular arguments, passing them every time the function is called. This has the downside of potentially creating bloated function calls, particularly when there is a standard default value that makes sense for most function evaluations.\nMost modern languages, including Julia, allow an alternate solution, which is to make these arguments optional. This involves setting a default value, which is used unless the argument is explicitly defined in a function call.\n\nfunction setting_optional_arguments(x, y, c=0.5)\n    return c * (x + y)\nend\n\nsetting_optional_arguments (generic function with 2 methods)\n\n\nIf we want to stick with the fixed value \\(c=0.5\\), all we have to do is call setting_optional_arguments with the x and y arguments.\n\nsetting_optional_arguments(3, 5)\n\n4.0\n\n\nOtherwise, we can pass a new value for c.\n\nsetting_optional_arguments(3, 5, 2)\n\n16\n\n\n\n\nPassing data structures as arguments\nInstead of passing variables individually, it may make sense to pass a data structure, such as an array or a tuple, and then unpacking within the function definition. This is straightforward in long form: access the appropriate elements using their index.\nIn short or anonymous form, there is a trick which allows the use of readable variables within the function definition.\n\nh₂((x,y)) = x*y # enclose the input arguments in parentheses to tell Julia to expect and unpack a tuple\n\nh₂ (generic function with 1 method)\n\n\n\nh₂((2, 3)) # this works perfectly, as we passed in a tuple\n\n6\n\n\n\nh₂(2, 3) # this gives an error, as h₂ expects a single tuple, not two different numeric values\n\nLoadError: MethodError: no method matching h₂(::Int64, ::Int64)\n\u001b[0mClosest candidates are:\n\u001b[0m  h₂(::Any) at In[50]:1\n\n\n\nh₂([3, 10]) # this also works with arrays instead of tuples\n\n30\n\n\n\n\nVectorized operations\nJulia uses dot syntax to vectorize an operation and apply it element-wise across an array.\nFor example, to calculate the square root of 3:\n\nsqrt(3)\n\n1.7320508075688772\n\n\nTo calculate the square roots of every integer between 1 and 5:\n\nsqrt.([1, 2, 3, 4, 5])\n\n5-element Vector{Float64}:\n 1.0\n 1.4142135623730951\n 1.7320508075688772\n 2.0\n 2.23606797749979\n\n\nThe same dot syntax is used for arithmetic operations over arrays, since these operations are really functions.\n\n[1, 2, 3, 4] .* 2\n\n4-element Vector{Int64}:\n 2\n 4\n 6\n 8\n\n\nVectorization can be faster and is more concise to write and read than applying the same function to multiple variables or objects explicitly, so take advantage!\n\n\nReturning multiple values\nYou can return multiple values by separating them with a comma. This implicitly causes the function to return a tuple of values.\n\nfunction return_multiple_values(x, y)\n    return x + y, x * y\nend\nreturn_multiple_values(3, 5)\n\n(8, 15)\n\n\nThese values can be unpacked into multiple variables.\n\nn, ν = return_multiple_values(3, 5)\nn\n\n8\n\n\n\nν\n\n15\n\n\n\n\nReturning nothing\nSometimes you don’t want a function to return any values at all. For example, you might want a function that only prints a string to the console.\n\nfunction print_some_string(x)\n    println(\"x: $x\")\n    return nothing\nend\nprint_some_string(42)\n\nx: 42"
  },
  {
    "objectID": "tutorials/julia-basics.html#printing-text-output",
    "href": "tutorials/julia-basics.html#printing-text-output",
    "title": "Tutorial: Julia Basics",
    "section": "Printing Text Output",
    "text": "Printing Text Output\nThe Text() function returns its argument as a plain text string. Notice how this is different from evaluating a string!\n\nText(\"I'm printing a string.\")\n\nI'm printing a string.\n\n\nText() is used in this tutorial as it returns the string passed to it. To print directly to the console, use println().\n\nprintln(\"I'm writing a string to the console.\")\n\nI'm writing a string to the console.\n\n\n\nPrinting Variables In a String\nWhat if we want to include the value of a variable inside of a string? We do this using string interpolation, using $variablename inside of the string.\n\nbar = 42\nText(\"Now I'm printing a variable: $bar\")\n\nNow I'm printing a variable: 42"
  },
  {
    "objectID": "tutorials/julia-basics.html#control-flows",
    "href": "tutorials/julia-basics.html#control-flows",
    "title": "Tutorial: Julia Basics",
    "section": "Control Flows",
    "text": "Control Flows\nOne of the tricky things about learning a new programming language can be getting used to the specifics of control flow syntax. These types of flows include conditional if-then-else statements or loops.\n\nConditional Blocks\nConditional blocks allow different pieces of code to be evaluated depending on the value of a boolean expression or variable. For example, if we wanted to compute the absolute value of a number, rather than using abs():\n\nfunction our_abs(x)\n    if x &gt;= 0\n        return x\n    else\n        return -x\n    end\nend\n\nour_abs (generic function with 1 method)\n\n\n\nour_abs(4)\n\n4\n\n\n\nour_abs(-4)\n\n4\n\n\nTo nest conditional statements, use elseif.\n\nfunction test_sign(x)\n    if x &gt; 0\n        return Text(\"x is positive.\")\n    elseif x &lt; 0\n        return Text(\"x is negative.\")\n    else\n        return Text(\"x is zero.\")\n    end\nend\n\ntest_sign (generic function with 1 method)\n\n\n\ntest_sign(-5)\n\nx is negative.\n\n\n\ntest_sign(0)\n\nx is zero.\n\n\n\n\nLoops\nLoops allow expressions to be evaluated repeatedly until they are terminated. The two main types of loops are while loops and for loops.\n\nWhile loops\nwhile loops continue to evaluate an expression so long as a specified boolean condition is true. This is useful when you don’t know how many iterations it will take for the desired goal to be reached.\n\nfunction compute_factorial(x)\n    factorial = 1\n    while (x &gt; 1)\n        factorial *= x\n        x -= 1\n    end\n    return factorial\nend\ncompute_factorial(5)\n\n120\n\n\n\nWhile loops can easily turn into infinite loops if the condition is never meaningfully updated. Be careful, and look there if your programs are getting stuck. Also, If the expression in a while loop is false when the loop is reached, the loop will never be evaluated.\n\n\n\nFor loops\nfor loops run for a finite number of iterations, based on some defined index variable.\n\nfunction add_some_numbers(x)\n    total_sum = 0 # initialize at zero since we're adding\n    for i=1:x # the counter i is updated every iteration\n        total_sum += i\n    end\n    return total_sum\nend\nadd_some_numbers(4)\n\n10\n\n\nfor loops can also iterate over explicitly passed containers, rather than iterating over an incrementally-updated index sequence. Use the in keyword when defining the loop.\n\nfunction add_passed_numbers(set)\n    total_sum = 0\n    for i in set # this is the syntax we use when we want i to correspond to different container values\n        total_sum += i\n    end\n    return total_sum\nend\nadd_passed_numbers([1, 3, 5])\n\n9"
  },
  {
    "objectID": "tutorials/julia-basics.html#linear-algebra",
    "href": "tutorials/julia-basics.html#linear-algebra",
    "title": "Tutorial: Julia Basics",
    "section": "Linear algebra",
    "text": "Linear algebra\nMatrices are defined in Julia as 2d arrays. Unlike basic arrays, matrices need to contain the same data type so Julia knows what operations are allowed. When defining a matrix, use semicolons to separate rows. Row elements should not be separated by commas.\n\ntest_matrix = [1 2 3; 4 5 6]\n\n2×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n\n\nYou can also specify matrices using spaces and newlines.\n\ntest_matrix_2 = [1 2 3\n                 4 5 6]\n\n2×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n\n\nFinally, matrices can be created using comprehensions by separating the inputs by a comma.\n\n[i*j for i in 1:1:5, j in 1:1:5]\n\n5×5 Matrix{Int64}:\n 1   2   3   4   5\n 2   4   6   8  10\n 3   6   9  12  15\n 4   8  12  16  20\n 5  10  15  20  25\n\n\nVectors are treated as 1d matrices.\n\ntest_row_vector = [1 2 3]\n\n1×3 Matrix{Int64}:\n 1  2  3\n\n\n\ntest_col_vector = [1; 2; 3]\n\n3-element Vector{Int64}:\n 1\n 2\n 3\n\n\nMany linear algebra operations on vectors and matrices can be loaded using the LinearAlgebra package."
  },
  {
    "objectID": "tutorials/julia-basics.html#package-management",
    "href": "tutorials/julia-basics.html#package-management",
    "title": "Tutorial: Julia Basics",
    "section": "Package management",
    "text": "Package management\nSometimes you might need functionality that does not exist in base Julia. Julia handles packages using the Pkg package manager. After finding a package which has the functions that you need, you have two options: 1. Use the package management prompt in the Julia REPL (the standard Julia interface; what you get when you type julia in your terminal). Enter this by typing ] at the standard green Julia prompt julia&gt;. This will become a blue pkg&gt;. You can then download and install new packages using add packagename. 2. From the standard prompt, enter using Pkg; Pkg.add(packagename). The packagename package can then be used by adding using packagename to the start of the script."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This page contains information about and a schedule of the homework assignments for the semester."
  },
  {
    "objectID": "assignments.html#general-information",
    "href": "assignments.html#general-information",
    "title": "Assignments",
    "section": "General Information",
    "text": "General Information\n\nWhile the instructions for each assignment are available through the linked pages for quick and public access, if you are in the class you must use the link provided in Ed Discussion to accept the assignment. This will ensure that:\n\nYou have compatible versions of all relevant packages provided in the environment;\nYou have a GitHub repository that you can use to share your code.\n\nSubmit assignments by 9:00pm Eastern Time on the due date on Gradescope.\nSubmissions must be PDFs. Make sure that you tag the pages corresponding to each question; points will be deducted otherwise.\nTo convert the assignment notebook to PDF, you can use VS Code to render the notebook to HTML, and then use your browser to print to PDF. If you have set up LaTeX with VS Code, you can convert directly to a PDF."
  },
  {
    "objectID": "assignments.html#schedule",
    "href": "assignments.html#schedule",
    "title": "Assignments",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\nAssignment\nInstructions\nRubric\nDue Date\n\n\n\n\nHW1\n\n\nFeb 09, 2024"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This is a 3 credit course offered as an elective, which counts towards the Environmental Systems and Data Analytics focus area.\n\n\n\n\n\n Vivek Srikrishnan\n viveks@cornell.edu\n 318 Riley-Robb\n\n\n\n\n\n\n TBD\n TBD\n TBD\n\n\n\n\n\n\n MWF\n 1:25-2:15pm\n TBD\n\n\n\n\n\n\nSimulations from numerical and statistical models are a key tool used to quantify and represent our understanding of many different environmental systems, including but not limited to the climate, sea levels, air pollution, and the electric power system. Data analysis of environmental observations and model simulations is an integral part of developing and evaluating models used to 1) test our assumptions about environmental system dynamics; 2) develop new insights into environmental processes; and 3) project future environmental conditions and outcomes. understand system dynamics and project future conditions and outcomes. This course will provide an overview of the use of simulation model development and evaluation in environmental data analysis. The goal is to provide students with a framework and an initial toolkit of methods that they can use to formulate and update hypotheses about data and models. Students will actively analyze and use real data from a variety of environmental systems. In particular, we will:\n\nlearn how to effectively use and critique data visualizations;\ninterpret graphical and quantitative summaries of data and model simulations;\ncalibrate statistical and numerical models;\napply statistical methods to simulate from calibrated models;\nassess and select models; and\nemulate computationally-complex models with simpler representations."
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "Syllabus",
    "section": "",
    "text": "This is a 3 credit course offered as an elective, which counts towards the Environmental Systems and Data Analytics focus area.\n\n\n\n\n\n Vivek Srikrishnan\n viveks@cornell.edu\n 318 Riley-Robb\n\n\n\n\n\n\n TBD\n TBD\n TBD\n\n\n\n\n\n\n MWF\n 1:25-2:15pm\n TBD\n\n\n\n\n\n\nSimulations from numerical and statistical models are a key tool used to quantify and represent our understanding of many different environmental systems, including but not limited to the climate, sea levels, air pollution, and the electric power system. Data analysis of environmental observations and model simulations is an integral part of developing and evaluating models used to 1) test our assumptions about environmental system dynamics; 2) develop new insights into environmental processes; and 3) project future environmental conditions and outcomes. understand system dynamics and project future conditions and outcomes. This course will provide an overview of the use of simulation model development and evaluation in environmental data analysis. The goal is to provide students with a framework and an initial toolkit of methods that they can use to formulate and update hypotheses about data and models. Students will actively analyze and use real data from a variety of environmental systems. In particular, we will:\n\nlearn how to effectively use and critique data visualizations;\ninterpret graphical and quantitative summaries of data and model simulations;\ncalibrate statistical and numerical models;\napply statistical methods to simulate from calibrated models;\nassess and select models; and\nemulate computationally-complex models with simpler representations."
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAt the end of this class, students will:\n\nAnalyze environmental datasets using simulations from calibrated models;\nInterpret and communicate properties of datasets and models using graphical summaries;\nAssess model fit and performance by analyzing predictive performance;\nSolve statistical and numerical modeling, calibration, and visualization problems using modern programming languages."
  },
  {
    "objectID": "syllabus.html#prerequisites-preparation",
    "href": "syllabus.html#prerequisites-preparation",
    "title": "Syllabus",
    "section": "Prerequisites & Preparation",
    "text": "Prerequisites & Preparation\nThe following courses/material would be ideal preparation:\n\nOne course in programming (e.g. CS 1110, 1112 or ENGRD/CEE 3200)\nOne course in probability or statistics (ENGRD 2700, CEE 3040, or equivalent)\nOne course in environmental systems (BEE 4750/5750, or equivalent)\n\nIn the absence of one or more these prerequisites, you can seek the permission of instructor.\n\n\n\n\n\n\nWhat If My Programming or Stats Skills Are Rusty?\n\n\n\nIf your programming or statistics skills are a little rusty, don’t worry! We will review concepts and build skills as needed."
  },
  {
    "objectID": "syllabus.html#typical-topics",
    "href": "syllabus.html#typical-topics",
    "title": "Syllabus",
    "section": "Typical Topics",
    "text": "Typical Topics\n\nIntroduction to exploratory data analysis;\nReview of probability and statistics;\nBayesian decision theory;\nPrinciples of data visualization;\nModel residuals and discrepancies;\nCensored, truncated, and missing data;\nStatistical methods for calibration;\nPredictive model assessment;\nEmulation with surrogate models"
  },
  {
    "objectID": "syllabus.html#course-philosophy-and-expectations",
    "href": "syllabus.html#course-philosophy-and-expectations",
    "title": "Syllabus",
    "section": "Course Philosophy and Expectations",
    "text": "Course Philosophy and Expectations\nThe goal of our course is to help you gain competancy and knowledge in the area of data analysis. This involves a dual responsibility on the part of the instructor and the student. As the instructor, my responsibility is to provide you with a structure and opportunity to learn. To this end, I will commit to:\n\nprovide organized and focused lectures, in-class activities, and assignments;\nencourage students to regularly evaluate and provide feedback on the course;\nmanage the classroom atmosphere to promote learning;\nschedule sufficient out-of-class contact opportunities, such as office hours;\nallow adequate time for assignment completion;\nmake lecture materials, class policies, activities, and assignments accessible to students.\n\nI encourage you to discuss any concerns with me during office hours or through a course communications channel! Please let me know if you do not feel that I am holding up my end of the bargain.\nStudents can optimize their performance in the course by:\n\nattending all lectures;\ndoing any required preparatory work before class;\nactively participating in online and in-class discussions;\nbeginning assignments and other work early;\nand attending office hours as needed."
  },
  {
    "objectID": "syllabus.html#community",
    "href": "syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nDiversity and Inclusion\nOur goal in this class is to foster an inclusive learning environment and make everyone feel comfortable in the classroom, regardless of social identity, background, and specific learning needs. As engineers, our work touches on many critical aspects of society, and questions of inclusion and social justice cannot be separated from considerations of how data are generated, collected, and analyzed.\nIn all communications and interactions with each other, members of this class community (students and instructors) are expected to be respectful and inclusive. In this spirit, we ask all participants to:\n\nshare their experiences, values, and beliefs;\nbe open to and respectful of the views of others; and\nvalue each other’s opinions and communicate in a respectful manner.\n\nPlease let me know if you feel any aspect(s) of class could be made more inclusive. Please also share any preferred name(s) and/or your pronouns with me if you wish: I use he/him/his, and you can refer to me either as Vivek or Prof. Srikrishnan.\n\n\n\n\n\n\nPlease, Be Excellent To Teach Other\n\n\n\nWe all make mistakes in our communications with one another, both when speaking and listening. Be mindful of how spoken or written language might be misunderstood, and be aware that, for a variety of reasons, how others perceive your words and actions may not be exactly how you intended them. At the same time, it is also essential that we be respectful and interpret each other’s comments and actions in good faith.\n\n\n\n\nStudent Accomodations\nLet me know if you have any access barriers in this course, whether they relate to course materials, assignments, or communications. If any special accomodations would help you navigate any barriers and improve your chances of success, please exercise your right to those accomodations and reach out to me as early as possible with your Student Disability Services (SDS) accomodation letter. This will ensure that we have enough time to make appropriate arrangements.\n\n\n\n\n\n\nIf you need more immediate accomodations, but do not yet have a letter, please let me know and then follow up with SDS.\n\n\n\n\n\nCourse Communications\nMost course communications will occur via Ed Discussion. Public Ed posts are generally preferred to private posts or emails, as other students can benefit from the discussions. If you would like to discuss something privately, please do reach out through email or a private Ed post (which will only be viewable by you and the course staff).\nAnnouncements will be made on the course website and in Ed. Emergency announcements will also be made on Canvas.\n\n\n\n\n\n\nEd Tips\n\n\n\n\nIf you wait until the day an assignment is due (or even late the previous night) to ask a question on Ed, there is a strong chance that I will not see your post prior to the deadline.\nBut if you see unanswered questions and you have some insight, please answer! This class will work best when we all work together as a community.\n\n\n\n\n\nMental Health Resources\nWe all have to take care of our mental health, just as we would our physical health. As a student, you may experience a range of issues which can negatively impact your mental health. Please do not ignore any of these stressors, or feel like you have to navigate these challenges alone! You are part of a community of students, faculty, and staff, who have a responsibility to look for one another’s well-being. If you are struggling with managing your mental health, or if you believe a classmate may be struggling, please reach out to the course instructor, the TA, or, for broader support, please take advantage of Cornell’s mental health resources.\n\n\n\n\n\n\nMental Health And This Class\n\n\n\nI am not a trained counselor, but I am here to support you in whatever capacity we can. You should never feel that you need to push yourself past your limits to complete any assignment for this class or any other. If we need to make modifications to the course or assignment schedule, you can certainly reach out to me, and all relevant discussions will be kept strictly confidential."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nAttendance\nAttendance is not required, but in general, students who attend class regularly will do better and get more out of the class than students who do not. Your class participation grade will reflect both the quantity and quality of your participation, only some of which can occur asynchronously. I will put as many course materials, such as lecture notes and announcements, as possible online, but viewing materials online is not the same as active participation and engagement. Life happens, of course, and this may lead you to miss class. Let me know if you need any appropriate arrangements ahead of time.\n\n\n\n\n\n\nWhat If I’m Sick?\n\n\n\nPlease stay home if you’re feeling sick! This is beneficial for both for your own recovery and the health and safety of your classmates. We will also make any necessary arrangements for you to stay on top of the class material and if whatever is going on will negatively impact your grade, for example by causing you to be unable to submit an assignment on time.\n\n\n\n\nMask Policies\nMasks are encouraged but not required in the classroom, per university policy. However, the University strongly encourages compliance with requests to mask from students, faculty, and staff who are concerned about the risk of infection. Please be respectful of these concerns and requests if you cannot wear a mask.\n\n\n\n\n\n\nMasks Will Be Required In My Office\n\n\n\nI will require masks to be worn in my office or during in-person office hours, as we are necessarily interacting in close quarters without great airflow.\n\n\n\n\nAcademic Integrity\n\n\n\n\n\n\nTL;DR: Don’t cheat, copy, or plagiarize!\n\n\n\nThis class is designed to encourage collaboration, and students are encouraged to discuss their work with other students. However, I expect students to abide by the Cornell University Code of Academic Integrity in all aspects of this class. All work submitted must represent the students’ own work and understanding, whether individually or as a group (depending on the particulars of the assignment). This includes analyses, code, software runs, and reports. Engineering as a profession relies upon the honesty and integrity of its practitioners (see e.g. the American Society for Civil Engineers’ Code of Ethics).\n\n\nExternal Resources\nThe collaborative environment in this class should not be viewed as an invitation for plagiarism. Plagiarism occurs when a writer intentionally misrepresents another’s words or ideas (including code!) as their own without acknowledging the source. All external resources which are consulted while working on an assignment should be referenced, including other students and faculty with whom the assignment is discussed. You will never be penalized for consulting an external source for help and referencing it, but plagiarism will result in a zero for that assignment as well as the potential for your case to be passed on for additional disciplinary action.\n\n\nAI/ML Resource Policy\nAs noted, all work submitted for a grade in this course must reflect your own understanding. The use and consulation of AI/ML tools, such as ChatGPT or similar, must be pre-approved and clearly referenced. If approved, you must:\n\nreference the URL of the service you are using, including the specific date you accessed it;\nprovide the exact query or queries used to interact with the tool; and\nreport the exact response received.\n\nFailure to attain prior approval or fully reference the interaction, as described above, will be treated as plagiarism and referred to the University accordingly.\n\n\nLate Work Policy\nIn general, late work will be subjected to a 10% penalty per day, which can accumulate to 100% of the total grade. However, sometimes things come up in life. Please reach out ahead of time if you have extenuating circumstances (including University-approved absences or illnesses) which would make it difficult for you to submit your work on time. Work which would be late for appropriate reasons will be given extensions and the late penalty will be waived."
  },
  {
    "objectID": "syllabus.html#assessments",
    "href": "syllabus.html#assessments",
    "title": "Syllabus",
    "section": "Assessments",
    "text": "Assessments\n\nApplication Exercises: 10%\nMost weeks, students will be given a set of exercises (typically involving analyzing a dataset, a model, or a figure) to complete. These will involve a small amount of programming or visual assessment of data or a figure. Application exercises will be provided the previous Friday and are intended to align with the content for the week, and solutions should be submitted by 9:00pm on the Friday at the end of the given week. Application exercise solutions should be submitted as a PDF on Gradescope. The lowest two of these will be dropped. Application exercises which involve programming will be distributed using GitHub Classroom.\n\n\nLabs: 20%\nApproximately 7 class periods will be dedicated to working on labs. These labs are intended to give you hands-on experience with new tools and/or methods, and will focus more on completing tasks and interpreting output than conceptual questions. Students should bring their laptops to class on these days; please prepare in advance by downloading the notebook and setting up the environment by running the first few cells.\nLab notebook solutions will be due by 9:00pm roughly one week after the in-class session. These should be submitted to Gradescope as a PDF. The lowest lab grade will be dropped.\n\n\nHomework Assignments: 40%\nApproximately 6 homework assignments will be assigned throughout the semester (roughly one per course module). You will typically have 2 weeks to work on each assignment, though this depends on the module length. Students are encouraged to collaborate and learn from each other on homework assignments, but each student must submit their own solutions reflecting their understanding of the material. Consulting and referencing external resources and your peers is encouraged (engineering is a collaborative discipline!), but plagiarism is a violation of academic integrity.\nSome notes on assignment and grading logistics:\n\nHomework assignments will be distributed using GitHub Classroom. Students should make sure they update their GitHub repositories as they work on the assignments; this helps with answering questions and gives you a backstop in case something goes wrong and you can’t submit your assignment on time.\nHomeworks are due by 9:00pm Eastern Time on the designed due date. Your assignment notebook (which include your writeup and codes) should be submitted to Gradescope as a PDF with the answers to each question tagged (a failure to do this will result in deductions).\nRubrics will be provided for the homeworks as part of the assignments.\nStudents in 5850 will be asked to complete additional homework problems which go more deeply into the underlying concepts or apply more advanced techniques.\nYour lowest homework grade will be dropped. We can discuss arrangements if multiple assignments will be missed for university-approved reasons, preferably ahead of time.\nRegrade requests for specific problems must be made within a week of the grading of that assignment. However, note that regrades can cut both ways: the TA can take away points as well!\n\n\n\nFinal Term Project: 30%\nThis course will culminate with a term project. The goal of this project is to apply and extend the tools and approaches we will learn in class. While we encourage drawing on other classes or interests when developing and working on your project, submitting work from another course or work which was completed prior to the course is not permitted.\nThe term project will be completed in small groups (2-3 students) for students enrolled in BEE 4850 and individually for those in BEE 5850. The final deliverable for this project will be a poster summarizing the project and results. Ahead of that, you will submit the following:\n\na proposal for feedback on the scope of your project; and\na mid-semester work plan providing more details on the project design.\n\nRubrics will be provided for the components of the project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BEE 4850/5850: Environmental Data Analysis and Simulation",
    "section": "",
    "text": "This is the course website for the Spring 2024 edition of BEE 4850/5850, Environmental Data Analysis and Simulation, taught at Cornell University by Vivek Srikrishnan."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "BEE 4850/5850: Environmental Data Analysis and Simulation",
    "section": "Course Information",
    "text": "Course Information\n\nDetails on the class and course policies are provided in the syllabus.\nTopics and weekly materials can be found in the schedule."
  },
  {
    "objectID": "index.html#software-tools",
    "href": "index.html#software-tools",
    "title": "BEE 4850/5850: Environmental Data Analysis and Simulation",
    "section": "Software Tools",
    "text": "Software Tools\n\nThis course will use the Julia programming language. Julia is a modern, free, open source language which is designed for scientific computing. No prior knowledge of Julia is required. My recommendation is to use Visual Studio Code with the official Julia extension for coding.\nAssignments will be distributed using GitHub Classroom. You should create a GitHub account, but we will walk through how to use it."
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "Labs",
    "section": "",
    "text": "This page contains information about and a schedule of the homework assignments for the semester."
  },
  {
    "objectID": "labs.html#general-information",
    "href": "labs.html#general-information",
    "title": "Labs",
    "section": "General Information",
    "text": "General Information\n\nYou can download each lab notebook through the link below..\nSubmit assignments by 9:00pm Eastern Time on the due date on Gradescope.\nSubmissions must be PDFs. Make sure that you tag the pages corresponding to each question; points will be deducted otherwise.\nTo convert the assignment notebook to PDF, you can use VS Code to render the notebook to HTML, and then use your browser to print to PDF. If you have set up LaTeX with VS Code, you can convert directly to a PDF."
  },
  {
    "objectID": "labs.html#schedule",
    "href": "labs.html#schedule",
    "title": "Labs",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\nLab\nInstructions\nRubric\nDue Date\n\n\n\n\nLab 1\n\n\nFeb 02, 2024"
  }
]